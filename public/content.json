[{"title":"libevent学习文档(三)working with event","date":"2017-08-04T10:23:33.000Z","path":"2017/08/04/libevent3/","text":"Events have similar lifecycles. Once you call a Libevent function to set up an event and associate it with an event base, it becomes initialized. At this point, you can add, which makes it pending in the base. When the event is pending, if the conditions that would trigger an event occur (e.g., its file descriptor changes state or its timeout expires), the event becomesactive, and its (user-provided) callback function is run. If the event is configured persistent, it remains pending. If it is not persistent, it stops being pending when its callback runs. You can make a pending event non-pending by deleting it, and you can add a non-pending event to make it pending again. 事件有相似的生命周期，一旦你调用libevent函数设置event和event_base关联后，event被初始化了。add这个事件会使它阻塞，当事件阻塞时，有触发事件的条件出现，事件会激活，回调函数会被调用。如果事件被设置为永久，它保持阻塞。如果不是永久，当事件的回调函数调用的时候就不阻塞了。可以通过删除一个事件使它由阻塞变为非阻塞。通过添加使它由非阻塞变为阻塞。 1234567891011121314#define EV_TIMEOUT 0x01#define EV_READ 0x02#define EV_WRITE 0x04#define EV_SIGNAL 0x08#define EV_PERSIST 0x10#define EV_ET 0x20typedef void (*event_callback_fn)(evutil_socket_t, short, void *);struct event *event_new(struct event_base *base, evutil_socket_t fd, short what, event_callback_fn cb, void *arg);void event_free(struct event *event); 通过event_new创建事件，通过event_free释放。 参数base 表示event绑定在那个event_base上, fd表示event关联的描述符， what表示事件的类型，是一个bitfield, 上面那些宏按位或，cb是事件回调函数，事件就绪后可以触发。event_free释放event事件。 All new events are initialized and non-pending. To make an event pending, call event_add() (documented below). To deallocate an event, call event_free(). It is safe to call event_free() on an event that is pending or active: doing so makes the event non-pending and inactive before deallocating it. 所有新创建的事件都是初始化的，并且非阻塞，调用event_add可以让一个事件变为阻塞。调用event_free释放event，在事件阻塞或者激活状态下调用event_free是安全的，这个函数会在释放event之前将事件变为非阻塞并且非激活状态。 EV_TIMEOUT This flag indicates an event that becomes active after a timeout elapses. EV_READ This flag indicates an event that becomes active when the provided file descriptor is ready for reading. EV_WRITE This flag indicates an event that becomes active when the provided file descriptor is ready for writing. EV_SIGNAL Used to implement signal detection. See “Constructing signal events” below. EV_PERSIST Indicates that the event is persistent. See “About Event Persistence” below. EV_ET Indicates that the event should be edge-triggered, if the underlying event_base backend supports edge-triggered events. EV_TIMEOUT：表示过一段事件后event变为active。 EV_READ：当文件描述可读的时候变为就绪。 EV_WRITE：当文件描述符可写的时候变为就绪。 EV_SIGNAL：信号事件的标记 EV_PERSIST：永久事件，下面会介绍。 EV_ET：如果后端支持边缘触发事件，那么事件是边缘触发的。 About Event Persistence By default, whenever a pending event becomes active (because its fd is ready to read or write, or because its timeout expires), it becomes non-pending right before its callback is executed. Thus, if you want to make the event pending again, you can call event_add() on it again from inside the callback function. If the EV_PERSIST flag is set on an event, however, the event is persistent. This means that event remains pending even when its callback is activated. If you want to make it non-pending from within its callback, you can call event_del() on it. The timeout on a persistent event resets whenever the event’s callback runs. Thus, if you have an event with flags EV_READ|EV_PERSIST and a timeout of five seconds, the event will become active: Whenever the socket is ready for reading. Whenever five seconds have passed since the event last became active. 默认情况下，当一个阻塞事件变为active时，(读事件可读，写事件可写，超时间到期等)，在事件对应的回调函数调用前该事件就会变为非阻塞的。因此，如果想要将事件变为阻塞，需要在事件的回调函数里调用event_add() 如果设置了EV_PERSIST 标记位， 那么事件就变味永久的，这意味着事件在回调函数触发时任然保持pending，如果你想要在回调函数调用后该事件变为非阻塞，需要调用event_del()。 当事件回调函数调用后超时会被重置，因此，如果事件带有EV_READ|EV_PERSIST标记，并且有5秒的超时值，如下情况事件会变为active： 1当socket可读时 2从上次变为active之后过了5秒后事件会变为active。 当事件的回调函数需要用到自己作为参数时候，需要将参数传递为 void *event_self_cbarg(); 代码例子123456789101112131415161718192021222324#include &lt;event2/event.h&gt;static int n_calls = 0;void cb_func(evutil_socket_t fd, short what, void *arg)&#123; struct event *me = arg; printf(\"cb_func called %d times so far.\\n\", ++n_calls); if (n_calls &gt; 100) event_del(me);&#125;void run(struct event_base *base)&#123; struct timeval one_sec = &#123; 1, 0 &#125;; struct event *ev; /* We're going to set up a repeating timer to get called called 100 times. */ ev = event_new(base, -1, EV_PERSIST, cb_func, event_self_cbarg()); event_add(ev, &amp;one_sec); event_base_dispatch(base);&#125; For performance and other reasons, some people like to allocate events as a part of a larger structure. For each use of the event, this saves them: The memory allocator overhead for allocating a small object on the heap. The time overhead for dereferencing the pointer to the struct event. The time overhead from a possible additional cache miss if the event is not already in the cache. 有时候开辟event作为一个较大结构体的一部分，可以节省在堆上开辟小对象的内存，也可以节省间接引用事件指针的事件和额外内存流失的处理。 文档的作者并不提倡用event_assign这个函数，推荐使用event_new，而且对于一些问题event_assign并不好调试 下面是使用event_assign的例子12345678910111213141516struct event_pair &#123; evutil_socket_t fd; struct event read_event; struct event write_event;&#125;;void readcb(evutil_socket_t, short, void *);void writecb(evutil_socket_t, short, void *);struct event_pair *event_pair_new(struct event_base *base, evutil_socket_t fd)&#123; struct event_pair *p = malloc(sizeof(struct event_pair)); if (!p) return NULL; p-&gt;fd = fd; event_assign(&amp;p-&gt;read_event, base, fd, EV_READ|EV_PERSIST, readcb, p); event_assign(&amp;p-&gt;write_event, base, fd, EV_WRITE|EV_PERSIST, writecb, p); return p;&#125; WARNINGNever call event_assign() on an event that is already pending in an event base. Doing so can lead to extremely hard-to-diagnose errors. If the event is already initialized and pending, call event_del() on it before you call event_assign() on it again. event在event_base中阻塞时不要调用event_assign()，否则会造成很难查找分析的问题，如果一个事件已经初始化并且pending了，需要调用event_del()删除他，然后再次调用event_assign()。 evtimer_assign和evsignal_assign分别是定时器和信号的注册函数。 由于调用event_assign()可能会造成版本兼容的问题，调用如下函数，可以获取到event运行时大小。size_t event_get_struct_event_size(void); This function returns the number of bytes you need to set aside for a struct event. As before, you should only be using this function if you know that heap-allocation is actually a significant problem in your program, since it can make your code much harder to read and write. 这个函数返回event结构体旁边的偏移位置的字节数，只有在你觉得堆开辟确实是一个难题的时候才采用这个方法。因为这么做会是你的代码更难去读和写。 事件的添加：int event_add(struct event ev, const struct timeval tv);Calling event_add on a non-pending event makes it pending in its configured base. The function returns 0 on success, and -1 on failure. If tv is NULL, the event is added with no timeout. Otherwise, tv is the size of the timeout in seconds and microseconds. If you call event_add() on an event that is already pending, it will leave it pending, and reschedule it with the provided timeout. If the event is already pending, and you re-add it with the timeout NULL, event_add() will have no effect. 调用event_add会让一个event变得pending，返回0表示成功，-1表示失败。如果tv设置为NULL，表示没有超时检测。否则，tv表示超时的秒数和毫秒。如果在一个pending的event上调用add，会使它pengding，并且根据超时值重新计时。 事件的删除：int event_del(struct event *ev); 事件删除函数，会将一个阻塞或者激活的事件变为非阻塞和非激活的，如果事件是非阻塞的或者非激活的，调用这个函数并没有什么影响。同样，返回0表示成功，-1表示失败。 优先级设置：int event_priority_set(struct event *event, int priority); 每个event_base有priorities，event可以设置从0到这个值之间的一个数，0表示成功，-1表示失败。优先级高的先处理，优先级低的后处理。如果不设置优先级，默认值为event_base中队列大小除以212345678910111213141516171819202122#include &lt;event2/event.h&gt;void read_cb(evutil_socket_t, short, void *);void write_cb(evutil_socket_t, short, void *);void main_loop(evutil_socket_t fd)&#123; struct event *important, *unimportant; struct event_base *base; base = event_base_new(); event_base_priority_init(base, 2); /* Now base has priority 0, and priority 1 */ important = event_new(base, fd, EV_WRITE|EV_PERSIST, write_cb, NULL); unimportant = event_new(base, fd, EV_READ|EV_PERSIST, read_cb, NULL); event_priority_set(important, 0); event_priority_set(unimportant, 1); /* Now, whenever the fd is ready for writing, the write callback will happen before the read callback. The read callback won't happen at all until the write callback is no longer active. */&#125; 除此之外，libevent还为我们提供了一些接口访问当前event_base 和event属性。12345678910111213141516int event_pending(const struct event *ev, short what, struct timeval *tv_out);#define event_get_signal(ev) /* ... */evutil_socket_t event_get_fd(const struct event *ev);struct event_base *event_get_base(const struct event *ev);short event_get_events(const struct event *ev);event_callback_fn event_get_callback(const struct event *ev);void *event_get_callback_arg(const struct event *ev);int event_get_priority(const struct event *ev);void event_get_assignment(const struct event *event, struct event_base **base_out, evutil_socket_t *fd_out, short *events_out, event_callback_fn *callback_out, void **arg_out); event_pending 获取当前event对应的what属性事件是否pending或者被激活，If it is, and any of the flags EV_READ, EV_WRITE, EV_SIGNAL, and EV_TIMEOUT are set in the whatargument, the function returns all of the flags that the event is currently pending or active on 任类型都可以设置到what参数里，这个函数返回当前pending或者激活状态的标记按位或。event_get_signal和event_get_fd返回event关联的信号id和文件描述符id， event_get_base返回event绑定的event_base，event_get_events返回event监听的事件集合，event_get_callback返回event的回调函数，以及event_get_callback_arg返回回调函数参数，event_get_priority返回event的优先级event_get_assignment这个函数返回event所有绑定的信息到对应的指针域，如果形参为NULL，表示忽略。\\12345678910111213141516171819202122232425262728293031#include &lt;event2/event.h&gt;#include &lt;stdio.h&gt;/* Change the callback and callback_arg of 'ev', which must not be * pending. */int replace_callback(struct event *ev, event_callback_fn new_callback, void *new_callback_arg)&#123; struct event_base *base; evutil_socket_t fd; short events; int pending; pending = event_pending(ev, EV_READ|EV_WRITE|EV_SIGNAL|EV_TIMEOUT, NULL); if (pending) &#123; /* We want to catch this here so that we do not re-assign a * pending event. That would be very very bad. */ fprintf(stderr, \"Error! replace_callback called on a pending event!\\n\"); return -1; &#125; event_get_assignment(ev, &amp;base, &amp;fd, &amp;events, NULL /* ignore old callback */ , NULL /* ignore old callback argument */); event_assign(ev, base, fd, events, new_callback, new_callback_arg); return 0;&#125; 还有个能只调用一次事件的创建接口 int event_base_once(struct event_base , evutil_socket_t, short, void ()(evutil_socket_t, short, void ), void , const struct timeval *); 这个函数不支持EV_SIGNAL 和 EV_PERSIST ，这个事件也不支持手动删除和激活。当该事件对应的回调函数触发后，该事件会自动从event_base中移除，并且libevent会析构掉该event。 激活event的接口 void event_active(struct event *ev, int what, short ncalls); 这个函数可以根据what(EV_READ, EV_WRITE,EV_TIMER等)将event设置为active，调用函数前，event是否为pengding并不影响，并且激活它并且变为非阻塞状态。在同一个事件递归的调用event_active会导致内存耗尽。 下面是一个错误例子1234567891011121314151617181920212223struct event *ev;static void cb(int sock, short which, void *arg) &#123; /* Whoops: Calling event_active on the same event unconditionally from within its callback means that no other events might not get run! */ event_active(ev, EV_WRITE, 0);&#125;int main(int argc, char **argv) &#123; struct event_base *base = event_base_new(); ev = event_new(base, -1, EV_PERSIST | EV_READ, cb, NULL); event_add(ev, NULL); event_active(ev, EV_WRITE, 0); event_base_loop(base, 0); return 0;&#125; 有两种改进的方式，一种是采用定时器，另一种是采用libevent提供的event_config_set_max_dispatch_interval 定时器的就是只调用一次loop，之后的回调函数cb会反复调用，因为cb内部发现event不是阻塞状态了，就要将event删除后再加入，loop内部检测到新的event，继续调用cb，反复调用cb1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950struct event *ev;struct timeval tv;static void cb(int sock, short which, void *arg) &#123; if (!evtimer_pending(ev, NULL)) &#123; event_del(ev); evtimer_add(ev, &amp;tv); &#125;&#125;int main(int argc, char **argv) &#123; struct event_base *base = event_base_new(); tv.tv_sec = 0; tv.tv_usec = 0; ev = evtimer_new(base, cb, NULL); evtimer_add(ev, &amp;tv); event_base_loop(base, 0); return 0;&#125; event_config_set_max_dispatch_interval设置了dispatch的时间间隔，每个一段时间才派发就绪时间，这样就不会导致递归造成的资源耗尽了。struct event *ev;static void cb(int sock, short which, void *arg) &#123; event_active(ev, EV_WRITE, 0);&#125;int main(int argc, char **argv) &#123; struct event_config *cfg = event_config_new(); /* Run at most 16 callbacks before checking for other events. */ event_config_set_max_dispatch_interval(cfg, NULL, 16, 0); struct event_base *base = event_base_new_with_config(cfg); ev = event_new(base, -1, EV_PERSIST | EV_READ, cb, NULL); event_add(ev, NULL); event_active(ev, EV_WRITE, 0); event_base_loop(base, 0); return 0;&#125; 今天的学习就到这里，这是我的公众号","categories":[{"name":"技术开发","slug":"tech","permalink":"http://www.limerence2017.com/categories/tech/"}],"tags":[{"name":"网络编程","slug":"网络编程","permalink":"http://www.limerence2017.com/tags/网络编程/"},{"name":"Linux环境编程","slug":"Linux环境编程","permalink":"http://www.limerence2017.com/tags/Linux环境编程/"}]},{"title":"Libevent学习笔记(四) bufferevent 的 concepts and basics","date":"2017-08-04T10:08:08.000Z","path":"2017/08/04/libevent4/","text":"Bufferevents and evbuffers Every bufferevent has an input buffer and an output buffer. These are of type “struct evbuffer”. When you have data to write on a bufferevent, you add it to the output buffer; when a bufferevent has data for you to read, you drain it from the input buffer. 每个bufferevents都会包含一个input的buffer和output的buffer,都是struct evbuffer类型， 如果你有数据想通过bufferevent发送，需要将数据放入output buffer里。如果要从bufferevent中读数据， 需要从input buffer里读取。 Callbacks and watermarks Every bufferevent has two data-related callbacks: a read callback and a write callback. By default, the read callback is called whenever any data is read from the underlying transport, and the write callback is called whenever enough data from the output buffer is emptied to the underlying transport. You can override the behavior of these functions by adjusting the read and write “watermarks” of the bufferevent. 每一个bufferevent都有两个回调函数，一个读回调和一个写回调函数，默认情况下，只要从底层传输读取数据就回触发读回调函数，当output buffer中足够多的数据排出就会触发写回调函数。而我的理解是，这里的足够多，默认情况下是排空， 用户可以通过调整读写水位来达到控制这些函数触发。 下面是libevent源码中的一些注释 12345678910111213/** A read or write callback for a bufferevent. The read callback is triggered when new data arrives in the input buffer and the amount of readable data exceed the low watermark which is 0 by default. The write callback is triggered if the write buffer has been exhausted or fell below its low watermark. @param bev the bufferevent that triggered the callback @param ctx the user-specified context for this bufferevent */ 到此为止总结下，bufferevent实际上是libevent为我们准备的一个缓存结构，将接受的数据缓存到input buffer供用户从中读取，用户将发送的数据缓存到output buffer进行发送。bufferevent的input buffer中有数据到来并且可读数据达到或超过读数据的低水位就会触发读回调函数，读数据的低水位默认是0,写回调函数会在outbuffer中的数据低于写的低水位时会触发。bufferevent会自己讲output中的内容发送出去，将接收到的内容放到input中。 Read low-water markWhenever a read occurs that leaves the bufferevent’s input buffer at this level or higher, the bufferevent’s read callback is invoked. Defaults to 0, so that every read results in the read callback being invoked. 只要读事件让bufferevent超过或者到达这个Read low-water 水位或者更高，读回调会被触发。默认情况下 Read low-water 是0，所以每次bufferevent 读数据都会导致读回调触发。 Read high-water markIf the bufferevent’s input buffer ever gets to this level, the bufferevent stops reading until enough data is drained from the input buffer to take us below it again. Defaults to unlimited, so that we never stop reading because of the size of the input buffer. 如果bufferevent 的 input buffer达到Read high-water水平，那么bufferevent会停止读，直到有数据从input中被用户取出使input buffer的水位线低于Read high-water， 默认情况下Read high-water是无穷大的，因此我们不会因为input buffer不够停止读。 Write low-water markWhenever a write occurs that takes us to this level or below, we invoke the write callback. Defaults to 0, so that a write callback is not invoked unless the output buffer is emptied. 当bufferevent写数据导致数据大小低于 Write low-water水平线，就回触发写回调函数。默认这个Write low-water值为0，因此只有当output buffer数据为空时才会触发写回调函数。 Write high-water markNot used by a bufferevent directly, this watermark can have special meaning when a bufferevent is used as the underlying transport of another bufferevent. See notes on filtering bufferevents below. 这个参数不会直接使用，当一个bufferevent作为参数传递给另一个bufferevent时可以做为特殊意义。filtering bufferevents可能会用到。 A bufferevent also has an “error” or “event” callback that gets invoked to tell the application about non-data-oriented events, like when a connection is closed or an error occurs. The following event flags are defined: 一个bufferevent也会有类似错误或者特殊事件的回调函数，这类函数触发后通知应用程序一些和数据无关的事件，比如当有连接关闭，或者错误出现可以触发这类函数。 BEV_EVENT_READINGAn event occured during a read operation on the bufferevent. See the other flags for which event it was. 在bufferevent上进行读操作 BEV_EVENT_WRITINGAn event occured during a write operation on the bufferevent. See the other flags for which event it was. 在bufferevent上进行写操作 BEV_EVENT_ERRORAn error occurred during a bufferevent operation. For more information on what the error was, call EVUTIL_SOCKET_ERROR(). bufferevent操作产生错误，通过EVUTIL_SOCKET_ERROR可以详细查看错误源 BEV_EVENT_TIMEOUTA timeout expired on the bufferevent. 超时事件 BEV_EVENT_EOFWe got an end-of-file indication on the bufferevent. 读到文件结束符 BEV_EVENT_CONNECTEDWe finished a requested connection on the bufferevent. 完成连接 Deferred callbacks By default, a bufferevent callbacks are executed immediately when the corresponding condition happens. (This is true of evbuffer callbacks too; we’ll get to those later.) This immediate invocation can make trouble when dependencies get complex. For example, suppose that there is a callback that moves data into evbuffer A when it grows empty, and another callback that processes data out of evbuffer A when it grows full. Since these calls are all happening on the stack, you might risk a stack overflow if the dependency grows nasty enough. To solve this, you can tell a bufferevent (or an evbuffer) that its callbacks should be deferred. When the conditions are met for a deferred callback, rather than invoking it immediately, it is queued as part of the event_loop() call, and invoked after the regular events’ callbacks. (Deferred callbacks were introduced in Libevent 2.0.1-alpha.) 默认情况下，bufferevent回调函数在条件符合时会立即执行。当情况复杂时这种立即出发的方式可能会造成问题，例如，假设有一个回调函数功能是在evbuffer A变空时向evbuffer A中放入数据， 另一个回调函数是在evbuffer A数据满的时候从中取出数据，由于这些操作是在栈上进行，这种做法会造成造成栈溢出，解决方法就是将回调函数延迟触发，条件满足时，将回调函数作为event_loop的一个部分 通过有规律的事件回调触发。 Option flags for bufferevents You can use one or more flags when creating a bufferevent to alter its behavior. Recognized flags are: 创建bufferevent时可以选择如下选项进行个性化设置 BEV_OPT_CLOSE_ON_FREEWhen the bufferevent is freed, close the underlying transport. This will close an underlying socket, free an underlying bufferevent, etc. 当bufferevent被释放，关闭底层传输，这个将会关闭底层socket，释放底层的bufferevent等。 BEV_OPT_THREADSAFEAutomatically allocate locks for the bufferevent, so that it’s safe to use from multiple threads. 为bufferevent自动上锁，多线程模式会安全。 BEV_OPT_DEFER_CALLBACKSWhen this flag is set, the bufferevent defers all of its callbacks, as described above. 设置bufferevent的callback延迟处理。 BEV_OPT_UNLOCK_CALLBACKSBy default, when the bufferevent is set up to be threadsafe, the bufferevent’s locks are held whenever the any user-provided callback is invoked. Setting this option makes Libevent release the bufferevent’s lock when it’s invoking your callbacks. 如果设置了线程安全选项，设置这个选项会使得调用我们的回调函数时释放锁。 Working with socket-based bufferevents 1创建bufferevent，成功返回bufferevent的指针，失败返回空，options是上面提到的选项。1234struct bufferevent *bufferevent_socket_new( struct event_base *base, evutil_socket_t fd, enum bufferevent_options options); 2连接函数 int bufferevent_socket_connect(struct bufferevent bev, struct sockaddr address, int addrlen); the address and addrlen arguments are as for the standard call connect(). If the bufferevent does not already have a socket set, calling this function allocates a new stream socket for it, and makes it nonblocking. If the bufferevent does have a socket already, calling bufferevent_socket_connect() tells Libevent that the socket is not connected, and no reads or writes should be done on the socket until the connect operation has succeeded. It is okay to add data to the output buffer before the connect is done. 如果bufferevent没有设置socket，调用这个函数会为它创建一个非阻塞socket 如果bufferevent有socket，调用这个函数会通知libevent在连接成功前不能调用读或者写。 在连接成功前可以向output buffer中添加数据。 下面是例子： 123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;event2/event.h&gt;#include &lt;event2/bufferevent.h&gt;#include &lt;sys/socket.h&gt;#include &lt;string.h&gt;void eventcb(struct bufferevent *bev, short events, void *ptr)&#123; if (events &amp; BEV_EVENT_CONNECTED) &#123; /* We're connected to 127.0.0.1:8080. Ordinarily we'd do something here, like start reading or writing. */ &#125; else if (events &amp; BEV_EVENT_ERROR) &#123; /* An error occured while connecting. */ &#125;&#125;int main_loop(void)&#123; struct event_base *base; struct bufferevent *bev; struct sockaddr_in sin; base = event_base_new(); memset(&amp;sin, 0, sizeof(sin)); sin.sin_family = AF_INET; sin.sin_addr.s_addr = htonl(0x7f000001); /* 127.0.0.1 */ sin.sin_port = htons(8080); /* Port 8080 */ bev = bufferevent_socket_new(base, -1, BEV_OPT_CLOSE_ON_FREE); bufferevent_setcb(bev, NULL, NULL, eventcb, NULL); if (bufferevent_socket_connect(bev, (struct sockaddr *)&amp;sin, sizeof(sin)) &lt; 0) &#123; /* Error starting connection */ bufferevent_free(bev); return -1; &#125; event_base_dispatch(base); return 0;&#125; Note that you only get a BEV_EVENT_CONNECTED event if you launch the connect() attempt using bufferevent_socket_connect(). If you call connect() on your own, the connection gets reported as a write. If you want to call connect() yourself, but still get receive a BEV_EVENT_CONNECTED event when the connection succeeds, call bufferevent_socket_connect(bev, NULL, 0) after connect() returns -1 with errno equal to EAGAIN or EINPROGRESS. 如果通过bufferevent_socket_connect连接，那么返回的事件是BEV_EVENT_CONNECTED ， 如果通过connect连接，那么返回的是write事件。如果调用了connect，还想捕捉到BEV_EVENT_CONNECTED 事件，可以继续调用bufferevent_socket_connect(bev,NULL, 0),返回值为-1，errno为EAGAIN或者EINPROGRESS 3释放bufferevent void bufferevent_free(struct bufferevent *bev);This function frees a bufferevent. Bufferevents are internally reference-counted, so if the bufferevent has pending deferred callbacks when you free it, it won’t be deleted until the callbacks are done. The bufferevent_free() function does, however, try to free the bufferevent as soon as possible. If there is pending data to write on the bufferevent, it probably won’t be flushed before the bufferevent is freed. If the BEV_OPT_CLOSE_ON_FREE flag was set, and this bufferevent has a socket or underlying bufferevent associated with it as its transport, that transport is closed when you free the bufferevent. 当bufferevent有延迟回调函数没处理，调用bufferevent_free并不会立即释放bufferevent，bufferevent内部是引用计数的，他能做到的是尽快释放，如果bufferevent上存在阻塞的数据还没有写，这部分数据在bufferevent释放前是不会被释放的。 4 其他的一些设置函数 是指bufferevent回调函数，以及获取回调函数 12345678910111213typedef void (*bufferevent_data_cb)(struct bufferevent *bev, void *ctx);typedef void (*bufferevent_event_cb)(struct bufferevent *bev, short events, void *ctx);void bufferevent_setcb(struct bufferevent *bufev, bufferevent_data_cb readcb, bufferevent_data_cb writecb, bufferevent_event_cb eventcb, void *cbarg);void bufferevent_getcb(struct bufferevent *bufev, bufferevent_data_cb *readcb_ptr, bufferevent_data_cb *writecb_ptr, bufferevent_event_cb *eventcb_ptr, void **cbarg_ptr); 5 读写生效函数，读写失效函数 void bufferevent_enable(struct bufferevent bufev, short events);void bufferevent_disable(struct bufferevent bufev, short events); short bufferevent_get_enabled(struct bufferevent *bufev);You can enable or disable the events EV_READ, EV_WRITE, or EV_READ|EV_WRITE on a bufferevent. When reading or writing is not enabled, the bufferevent will not try to read or write data. There is no need to disable writing when the output buffer is empty: the bufferevent automatically stops writing, and restarts again when there is data to write. Similarly, there is no need to disable reading when the input buffer is up to its high-water mark: the bufferevent automatically stops reading, and restarts again when there is space to read. By default, a newly created bufferevent has writing enabled, but not reading. You can call bufferevent_get_enabled() to see which events are currently enabled on the bufferevent. 可以设置bufferevent 读，写，或者读和写生效，当读或者写失效，bufferevent将不会尝试读或者写数据。在output为空时没必要让写操作失效，bufferevent会自动停止写，当有数据可写时才再次执行写操作。 同样的，在input buffer超过高水位时，没必要设置读失效，bufferevent 会自动停止读，而等到有空间(其实是input缓冲区非满)再次开始接收数据。 默认情况下，新创建的 bufferevent是可写的不可读的。(因为如果设置可读选项，那么会出现busyloop，因为input一直非满) 用户可以通过bufferevent_get_enabled获取当前哪些事件类型是允许的。 6设置水位接口 void bufferevent_setwatermark(struct bufferevent *bufev, short events, size_t lowmark, size_t highmark);The bufferevent_setwatermark() function adjusts the read watermarks, the write watermarks, or both, of a single bufferevent. (If EV_READ is set in the events field, the read watermarks are adjusted. If EV_WRITE is set in the events field, the write watermarks are adjusted.) A high-water mark of 0 is equivalent to “unlimited”. bufferevent_setwatermark函数调整读或者写的水位。 7获取读写缓冲区的内容 struct evbuffer bufferevent_get_input(struct bufferevent bufev);struct evbuffer bufferevent_get_output(struct bufferevent bufev); 8向bufferevent中写数据 int bufferevent_write(struct bufferevent bufev, const void data, size_t size);int bufferevent_write_buffer(struct bufferevent bufev, struct evbuffer buf); 调用bufferevent_write可以向bufev的output 的末尾追加写入。 bufferevent_write_buffer将buf中的数据移除，写入到bufevoutput中。 两个函数返回0表示成功，-1表示失败。 9从bufferevent中读数据 size_t bufferevent_read(struct bufferevent bufev, void data, size_t size);int bufferevent_read_buffer(struct bufferevent bufev, struct evbuffer buf); bufferevent_read 从bufev中input buffer 读取size大小数据，存在data中。 bufferevent_read_buffer从bufev的input buffer中将所有数据取出放入到buf中。 两个函数返回0表示成功，-1表示失败。 10设置读写事件的超时时间 void bufferevent_set_timeouts(struct bufferevent bufev, const struct timeval timeout_read, const struct timeval *timeout_write); 11强制刷新读或者写 int bufferevent_flush(struct bufferevent *bufev, short iotype, enum bufferevent_flush_mode state); 强制从底层读取数据，或将数据写入底层。The iotype argument should be EV_READ, EV_WRITE, or EV_READ|EV_WRITE to indicate whether bytes being read, written, or both should be processed.","categories":[{"name":"技术开发","slug":"tech","permalink":"http://www.limerence2017.com/categories/tech/"}],"tags":[{"name":"网络编程","slug":"网络编程","permalink":"http://www.limerence2017.com/tags/网络编程/"},{"name":"Linux环境编程","slug":"Linux环境编程","permalink":"http://www.limerence2017.com/tags/Linux环境编程/"}]},{"title":"Libevent学习笔记(五) 根据例子学习bufferevent","date":"2017-08-04T09:41:54.000Z","path":"2017/08/04/Libevent5/","text":"libevent中提供了一个Hello-world.c 的例子，从这个例子可以学习libevent是如何使用bufferevent的。这个例子在Sample中这个例子之前讲解过，这次主要看下bufferevent的使用。 第一步找到main函数main函数 1234567891011121314151617181920int main()&#123; //...listener = evconnlistener_new_bind(base, listener_cb, (void *)base, LEV_OPT_REUSEABLE|LEV_OPT_CLOSE_ON_FREE, -1, (struct sockaddr*)&amp;sin, sizeof(sin)); //... event_base_dispatch(base); evconnlistener_free(listener); event_free(signal_event); event_base_free(base); printf(\"done\\n\"); return 0;&#125; main函数中调用evconnlistener_new_bind()创建了一个evconnlistener 类型的listener,然后拍发消息，之后释放各种资源。 第二步在evconnlistener_new_bind()中调用evconnlistener_new()完成listener属性设置。这个函数里对evconnlistener_event中base进行回调函数的绑定和参数设置，通过event_assign将evconnlistener_event的istener设置读事件的回调函数，并且通过evconnlistener_enable让读回调函数触发，也就是触发listener_read_cb。这里evconnlister_enable调用的也是结构体注册的enable具体看代码吧，调用的是r = lev-&gt;ops-&gt;enable(lev);等同于调用event_listener_enable，该函数内部完成event_add。 123456789101112131415161718192021222324252627282930313233struct evconnlistener_event &#123; struct evconnlistener base; struct event listener;&#125;;struct evconnlistener *evconnlistener_new(struct event_base *base, evconnlistener_cb cb, void *ptr, unsigned flags, int backlog, evutil_socket_t fd)&#123; struct evconnlistener_event *lev;//开辟evconnlistener_event大小区域 lev = mm_calloc(1, sizeof(struct evconnlistener_event)); if (!lev) return NULL; //lev -&gt; base 表示 evconnlistener //evconnlistener evconnlistener_ops 基本回调参数和回调函数结构体赋值 lev-&gt;base.ops = &amp;evconnlistener_event_ops; //evconnlistener_cb 设置为listener_cb lev-&gt;base.cb = cb; //ptr表示event_base 指针 lev-&gt;base.user_data = ptr; lev-&gt;base.flags = flags; lev-&gt;base.refcnt = 1;// lev is evconnlistener_event //lev-&gt;listener is event //为lev-&gt;listener设置读回调函数和读关注事件，仅进行设置并没加入event队列 event_assign(&amp;lev-&gt;listener, base, fd, EV_READ|EV_PERSIST, listener_read_cb, lev); //实际调用了event_add将事件加入event队列 evconnlistener_enable(&amp;lev-&gt;base); return &amp;lev-&gt;base;&#125; 第三步listener_read_cb内部调用accept生成新的socket处理连接，调用listener_cb新的socket作为参数传递给evconnlistener_event中base的回调函数listener_cb 123456789101112131415161718192021222324252627282930static voidlistener_read_cb(evutil_socket_t fd, short what, void *p)&#123; struct evconnlistener *lev = p; int err; evconnlistener_cb cb; evconnlistener_errorcb errorcb; void *user_data; LOCK(lev); while (1) &#123; //...//cb 就 是 listener_cb cb = lev-&gt;cb; user_data = lev-&gt;user_data; UNLOCK(lev); //触发了listener_cb //完成了eventbuffer注册写和事件函数 cb(lev, new_fd, (struct sockaddr*)&amp;ss, (int)socklen, user_data); LOCK(lev); if (lev-&gt;refcnt == 1) &#123; int freed = listener_decref_and_unlock(lev); EVUTIL_ASSERT(freed); return; &#125; --lev-&gt;refcnt; &#125; //...&#125; 第四步listener_cb 调用bufferevent_socket_new 生成bufferevent，然后bufferevent_setcb设置读写水位触发的回调函数，bufferevent_enable将bufferevent的写事件加入监听，即开始检测写事件。关闭读事件，并且向outbuf中写入MSGbufferevent_socket_new内部绑定bufferevent的读写事件回调函数，读事件为bufev-&gt;ev_read，绑定了bufferevent_readcb回调函数，写事件为bufev-&gt;ev_write，绑定了bufferevent_writecb回调函数。这两个回调函数和bufferevent的readcb和writecb是不一样的，这两个函数在对应的读写事件激活时才触发。而readcb和writecb是基于水位线达到阈值才会触发。做好区分。bufferevent_socket_new内部还对bufev-&gt;output添加了对调函数bufferevent_socket_outbuf_cb，bufferevent_socket_outbuf_cb内部检测是否开启写事件，以及是否可写，如果可写，同样将写事件加入监听队列，也就是调用了event_add。bufferevent_socket_new内部解释完毕了。bufferevent_setcb设置的是读写水位达到阈值后的回调函数，bufferevent_enable内部也是调用了event_add，将读事件加入监听队列。bufferevent_enable内部调用bufev-&gt;be_ops-&gt;enable(bufev, impl_events)，等同于be_socket_enable，另外bufferevent_write函数内部调用evbuffer_add，evbuffer_add内部调用了evbuffer_invoke_callbacks，就会调用绑定在output buffer上的回调函数bufferevent_socket_outbuf_cb。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162static voidlistener_cb(struct evconnlistener *listener, evutil_socket_t fd, struct sockaddr *sa, int socklen, void *user_data)&#123; struct event_base *base = user_data; struct bufferevent *bev; bev = bufferevent_socket_new(base, fd, BEV_OPT_CLOSE_ON_FREE); if (!bev) &#123; fprintf(stderr, \"Error constructing bufferevent!\"); event_base_loopbreak(base); return; &#125; //设置写回调和事件回调 bufferevent_setcb(bev, NULL, conn_writecb, conn_eventcb, NULL); bufferevent_enable(bev, EV_WRITE); bufferevent_disable(bev, EV_READ); //将要发送的内容写入evbuffer结构 bufferevent_write(bev, MESSAGE, strlen(MESSAGE));&#125;``` cpp ``` cppstruct bufferevent *bufferevent_socket_new(struct event_base *base, evutil_socket_t fd, int options)&#123; struct bufferevent_private *bufev_p; struct bufferevent *bufev; //...//设置bufferevent中 ev_read(event类型)回调函数 event_assign(&amp;bufev-&gt;ev_read, bufev-&gt;ev_base, fd, EV_READ|EV_PERSIST, bufferevent_readcb, bufev); //设置bufferevent中 ev_write(event类型)回调函数 event_assign(&amp;bufev-&gt;ev_write, bufev-&gt;ev_base, fd, EV_WRITE|EV_PERSIST, bufferevent_writecb, bufev); //为bufev-&gt;output(evbuffer类型)设置回调函数，插入bufferevent-&gt;output的callback队列 //bufferevent_socket_outbuf_cb回调函数内部将ev_write事件加入事件队列 evbuffer_add_cb(bufev-&gt;output, bufferevent_socket_outbuf_cb, bufev); evbuffer_freeze(bufev-&gt;input, 0); evbuffer_freeze(bufev-&gt;output, 1); //... return bufev;&#125;``` ``` cppstatic intbe_socket_enable(struct bufferevent *bufev, short event)&#123; if (event &amp; EV_READ) &#123; if (be_socket_add(&amp;bufev-&gt;ev_read,&amp;bufev-&gt;timeout_read) == -1) return -1; &#125; if (event &amp; EV_WRITE) &#123; if (be_socket_add(&amp;bufev-&gt;ev_write,&amp;bufev-&gt;timeout_write) == -1) return -1; &#125; return 0;&#125; 第五步 bufferevent的output中写入MSG， 并且之前也已经将EV_WRITE事件加入监听，所以内核检测到socket可写，会通知bufferevent的ev_write，调用绑定在ev_write上的函数bufferevent_writecb。这是bufferevent内部的写操作，我们可以详细看一下。之前也有讲过bufferevent会将接收到的数据放到inputbuffer中，将outputbuffer中的数据发送。所以之前讲过的接口bufferevent_write让我们将要发送的数据放到output中，bufferevent_read可以从input中读出bufferevent接收到的数据。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128static voidbufferevent_writecb(evutil_socket_t fd, short event, void *arg)&#123; struct bufferevent *bufev = arg; struct bufferevent_private *bufev_p = EVUTIL_UPCAST(bufev, struct bufferevent_private, bev); int res = 0; short what = BEV_EVENT_WRITING; int connected = 0; ev_ssize_t atmost = -1; //对 bufferevent加锁，支持多线程安全模式 _bufferevent_incref_and_lock(bufev); //检测是否带有超时事件 if (event == EV_TIMEOUT) &#123; /* Note that we only check for event==EV_TIMEOUT. If * event==EV_TIMEOUT|EV_WRITE, we can safely ignore the * timeout, since a read has occurred */ what |= BEV_EVENT_TIMEOUT; goto error; &#125; //判断是否是连接事件 if (bufev_p-&gt;connecting) &#123; int c = evutil_socket_finished_connecting(fd); /* we need to fake the error if the connection was refused * immediately - usually connection to localhost on BSD */ if (bufev_p-&gt;connection_refused) &#123; bufev_p-&gt;connection_refused = 0; c = -1; &#125; if (c == 0) goto done; bufev_p-&gt;connecting = 0; //连接失败删除该事件 if (c &lt; 0) &#123; event_del(&amp;bufev-&gt;ev_write); event_del(&amp;bufev-&gt;ev_read); _bufferevent_run_eventcb(bufev, BEV_EVENT_ERROR); goto done; &#125; else &#123; connected = 1; //windows情况下直接运行事件回调函数，然后go done#ifdef WIN32 if (BEV_IS_ASYNC(bufev)) &#123; event_del(&amp;bufev-&gt;ev_write); bufferevent_async_set_connected(bufev); _bufferevent_run_eventcb(bufev, BEV_EVENT_CONNECTED); goto done; &#125;#endif //linux 下 运行事件回调函数 _bufferevent_run_eventcb(bufev, BEV_EVENT_CONNECTED); //检测是否可写，不可写删除该事件 if (!(bufev-&gt;enabled &amp; EV_WRITE) || bufev_p-&gt;write_suspended) &#123; event_del(&amp;bufev-&gt;ev_write); goto done; &#125; &#125; &#125; //计算bufferevent能写的最大数量 atmost = _bufferevent_get_write_max(bufev_p); //写事件挂起了，跳过。 if (bufev_p-&gt;write_suspended) goto done; //output非空 if (evbuffer_get_length(bufev-&gt;output)) &#123; //将output的头打开，从头部发送 evbuffer_unfreeze(bufev-&gt;output, 1); //bufferevent调用写操作，将outbuffer中的内容发送出去 res = evbuffer_write_atmost(bufev-&gt;output, fd, atmost); //将output的头部关闭 evbuffer_freeze(bufev-&gt;output, 1); if (res == -1) &#123; int err = evutil_socket_geterror(fd); if (EVUTIL_ERR_RW_RETRIABLE(err)) goto reschedule; what |= BEV_EVENT_ERROR; &#125; else if (res == 0) &#123; /* eof case XXXX Actually, a 0 on write doesn't indicate an EOF. An ECONNRESET might be more typical. */ //写完了 what |= BEV_EVENT_EOF; &#125; if (res &lt;= 0) goto error; //bufferevent减少发送的大小，留下未发送的，下次再发送，因为是PERSIST|WRITE //所以会在下次检测到可写时候继续写 _bufferevent_decrement_write_buckets(bufev_p, res); &#125; //计算是否将outbuf中的内容发送完，发完了就删除写事件 if (evbuffer_get_length(bufev-&gt;output) == 0) &#123; event_del(&amp;bufev-&gt;ev_write); &#125; /* * Invoke the user callback if our buffer is drained or below the * low watermark. */ //将buffer中的内容发完，或者低于low 水位，那么调用用户注册的写回调函数 //之前注册在bufev-&gt;writecb中的回调函数 if ((res || !connected) &amp;&amp; evbuffer_get_length(bufev-&gt;output) &lt;= bufev-&gt;wm_write.low) &#123; _bufferevent_run_writecb(bufev); &#125; goto done; reschedule: if (evbuffer_get_length(bufev-&gt;output) == 0) &#123; event_del(&amp;bufev-&gt;ev_write); &#125; goto done; error: bufferevent_disable(bufev, EV_WRITE); _bufferevent_run_eventcb(bufev, what); done: _bufferevent_decref_and_unlock(bufev);&#125; 第六步：这个函数内部每次尽可能多的发送数据，没有发送完就下次轮询继续发送,直到水位低于或等于写数据的低水位，那么就会触发bufferevent低水位写回调函数。也就是conn_writecb， 在conn_writecb内部检测output buffer中数据为空，就释放该bufferevent。 123456789static voidconn_writecb(struct bufferevent *bev, void *user_data)&#123; struct evbuffer *output = bufferevent_get_output(bev); if (evbuffer_get_length(output) == 0) &#123; printf(\"flushed answer\\n\"); bufferevent_free(bev); &#125;&#125; 这就是整体流程，bufferevent内部的流畅看懂即可，我们只需要使用libevent提供的接口即可。","categories":[{"name":"技术开发","slug":"tech","permalink":"http://www.limerence2017.com/categories/tech/"}],"tags":[{"name":"网络编程","slug":"网络编程","permalink":"http://www.limerence2017.com/tags/网络编程/"},{"name":"Linux环境编程","slug":"Linux环境编程","permalink":"http://www.limerence2017.com/tags/Linux环境编程/"}]},{"title":"网络编程的一些错误总结","date":"2017-08-04T09:28:12.000Z","path":"2017/08/04/neterror/","text":"最近自己在写一套服务器框架，期间遇到很多问题，对于Linux或者windows出错情况下可以通过错误码获取错误信息。为了测试服务器性能，我在客户端开了2000个线程，这样每个线程都创建socket和服务器通信，连接15个线程，再后来的客户端线程connect过程中会失败，我另起了一个客户端进程进行连接，还是能连接15个过后才出现问题，初步可以排除服务器并没有达到连接上限，之后在linux上打印该错误码为111，查询意思为服务器拒绝客户端连接。查询相关资料是监听队列设置为5，只能接受一部分剩余的由于监听队列满了就被拒绝了。之后查询libevent和redis库的一些监听队列大小，设置为128较为合适，这次同样会出现一部分客户端连接失败，因为监听队列总是有限的，尽管如此，极限的情况下一秒同时连接500多个客户端还是没问题。这个监听队列的知识可以介绍下：这个图说明tcp是三次握手处理连接和四次握手处理断开。 listen函数将主动套接字转换为被动监控套接字，其第二个参数backlog决定了内核的连接缓存队列长度。对于一个给定的监听套接字，内核维护两个队列： ① 未就绪队列，存放没有完成三路握手的连接，监听套接字收到SYN并返回ACK+SYN，连接处于SYN_RECV状态，等待对端发送ACK。如果已完成队列非满，则接收ACK，连接握手完成，进入已完成队列；如果已完成队列满则丢弃ACK，对端重发ACK（对端看到的连接是ESTABLISED状态），若未就绪队列中的SYN_RECV等待直到超时还没进入已完成队列则丢弃连接（对端不知道，只有在读写套接字时才知道）。 ② 已完成队列，存放已经完成三路握手的连接（ESTABLISHED），等待accept取走连接。 backlog决定了两个队列的长度之和（并不是说两个队列之和等于backlog，而是存在个转换，依赖于具体实现）。 如果未就绪队列满则忽略新到来的SYN请求，对端重发，如果一直不能进入未就绪队列则对端connect失败返回。 除此之外，由于每个客户端进程我开辟了2000个线程，也会报错errorno为9，意为bad file discirp，错误的文件描述符。 因为linux限制每个进程最多开辟1024个线程。 这些都是实际开发中遇到的一些问题，总结出来以便更好地处理以后的问题。","categories":[{"name":"技术开发","slug":"tech","permalink":"http://www.limerence2017.com/categories/tech/"}],"tags":[{"name":"网络编程","slug":"网络编程","permalink":"http://www.limerence2017.com/tags/网络编程/"}]},{"title":"网络编程一些常见问题总结","date":"2017-08-04T09:19:14.000Z","path":"2017/08/04/newproblem/","text":"1 设置网络socket非阻塞：12u_long has = 1;ioctl(m_sock, FIONBIO , &amp;has); 这个函数很有可能返回success，却并没有设置成功。windows对此有优化，对于linux版本应采用fcntl设置。 总结如下：123456789101112131415161718192021222324252627intmake_socket_nonblocking(sockfd fd)&#123;#ifdef WIN32 &#123; u_long nonblocking = 1; if (ioctlsocket(fd, FIONBIO, &amp;nonblocking) == SOCKET_ERROR) &#123; cout &lt;&lt; \"fcntl failed, fd is : \" &lt;&lt; fd; return -1; &#125; &#125;#else &#123; int flags; if ((flags = fcntl(fd, F_GETFL, NULL)) &lt; 0) &#123; cout &lt;&lt; \"fcntl failed, fd is : \" &lt;&lt; fd; return -1; &#125; if (fcntl(fd, F_SETFL, flags | O_NONBLOCK) == -1) &#123; cout &lt;&lt; \"fcntl failed, fd is : \" &lt;&lt; fd; return -1; &#125; &#125;#endif return 0;&#125; 2 windows环境下查看错误123使用WSAGetLastError函数需要配置 lib,\"ws2_32.lib\" 3 EPOLLET这个宏是最小intEPOLLET这个宏的数值为-2147483648， 是能表示的最小int值。 4 make: 警告：检测到时钟错误。您的创建可能是不完整的。可以通过ls -l查看具体的是哪个文件的时间错了，就可以对症下药了，直接 “ touch 对应文件 “ 就可以解决这个问题。 或者读者可以用 “ touch * “ 来更新整个项目文件的时间,这也可以解决问题。 5 select fd_set 对于不同平台实现是不同的在windows平台实现1234typedef struct fd_set &#123; u_int fd_count; /* how many are SET? */ SOCKET fd_array[FD_SETSIZE]; /* an array of SOCKETs */&#125; fd_set; 很明了，一个计数的fd_count，另一个就是SOCKET数组。其中，FD_SETSIZE是可以设置的。整个fd_set的过程实际上就是将对应的fd_count作为数组下标，数组元素存储的是对应socket fd。比如说当前读事件集合readset的fd_count 为7，当要监控socket fd为5 的读事件到来时，那么readset这个集合中下标为8的数组元素为5，fd_count = 8以此类推。当调用select时，会返回对应读，写集合所有的描述符数组，并且重置内部的fd_count数量，然后分别调用读写函数即可。 下面是fd_set在linux下的实现：123456789101112typedef struct &#123; /* XPG4.2 requires this member name. Otherwise avoid the name from the global namespace. */#ifdef __USE_XOPEN __fd_mask fds_bits[__FD_SETSIZE / __NFDBITS];# define __FDS_BITS(set) ((set)-&gt;fds_bits)#else __fd_mask __fds_bits[__FD_SETSIZE / __NFDBITS];# define __FDS_BITS(set) ((set)-&gt;__fds_bits)#endif &#125; fd_set; 根据UNIX网络编程对fd_set的介绍，fd_set是个整数数组，用每个bit位来表示fd的。比如，一个32位整数，则数组第一个整数表示0-31的fd，以此类推，第二个整数表示32-63查看linux的FD_SET、FD_CLR是用汇编实现的。根据说明可以知道，就是给bit置位。fd_set在不同平台实现的机制不一样，select第一个参数在linux环境下表示最大描述符数+1。windows无意义。 下面是我根据libevent早期版本实现的一套select模型：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323#include \"modelmanager.h\"#ifdef WIN32#include \"netmodeldef.h\"#define XFREE(ptr) do &#123; if (ptr) free(ptr); &#125; while (0)struct win_fd_set &#123; u_int fd_count; SOCKET fd_array[1];&#125;;struct win32op &#123; unsigned num_fds_in_fd_sets; int resize_out_sets; struct win_fd_set *readset_in; struct win_fd_set *writeset_in; struct win_fd_set *readset_out; struct win_fd_set *writeset_out; struct win_fd_set *exset_out; unsigned signals_are_broken : 1;&#125;;static void *win32_init(void *);static int win32_add(void *, sockfd, short old, short events, void *_idx);static int win32_del(void *, sockfd, short old, short events, void *_idx);static int win32_dispatch(void *base, struct timeval *);static void win32_dealloc(void *);struct ModelOp win32ops = &#123; \"win32\", win32_init, win32_add, win32_del, win32_dispatch, win32_dealloc,&#125;;#define FD_SET_ALLOC_SIZE(n) ((sizeof(struct win_fd_set) + ((n)-1)*sizeof(SOCKET)))static intgrow_fd_sets(struct win32op *op, unsigned new_num_fds)&#123; size_t size; if( !(new_num_fds &gt;= op-&gt;readset_in-&gt;fd_count &amp;&amp; new_num_fds &gt;= op-&gt;writeset_in-&gt;fd_count) ) return -1; if( !(new_num_fds &gt;= 1) ) return -1; size = FD_SET_ALLOC_SIZE(new_num_fds); if (!(op-&gt;readset_in = (struct win_fd_set *)realloc(op-&gt;readset_in, size))) return (-1); if (!(op-&gt;writeset_in = (struct win_fd_set *)realloc(op-&gt;writeset_in, size))) return (-1); op-&gt;resize_out_sets = 1; op-&gt;num_fds_in_fd_sets = new_num_fds; return (0);&#125;static intdo_fd_set(struct win32op *op, struct SocketIndex *ent, SOCKET s, int read)&#123; struct win_fd_set *set = read ? op-&gt;readset_in : op-&gt;writeset_in; if (read) &#123; if (ent-&gt;read_pos_plus1 &gt; 0) return (0); &#125; else &#123; if (ent-&gt;write_pos_plus1 &gt; 0) return (0); &#125; if (set-&gt;fd_count == op-&gt;num_fds_in_fd_sets) &#123; if (grow_fd_sets(op, op-&gt;num_fds_in_fd_sets*2)) return (-1); // set pointer will have changed and needs reiniting! set = read ? op-&gt;readset_in : op-&gt;writeset_in; &#125; set-&gt;fd_array[set-&gt;fd_count] = s; if (read) ent-&gt;read_pos_plus1 = set-&gt;fd_count+1; else ent-&gt;write_pos_plus1 = set-&gt;fd_count+1; return (set-&gt;fd_count++);&#125;static intdo_fd_clear(void *base,struct win32op *op, struct SocketIndex *ent, int read)&#123; ModelManager* pDispatcher = (ModelManager*)base; int i; struct win_fd_set *set = read ? op-&gt;readset_in : op-&gt;writeset_in; if (read) &#123; i = ent-&gt;read_pos_plus1 - 1; ent-&gt;read_pos_plus1 = 0; &#125; else &#123; i = ent-&gt;write_pos_plus1 - 1; ent-&gt;write_pos_plus1 = 0; &#125; if (i &lt; 0) return (0); if (--set-&gt;fd_count != (unsigned)i) &#123; struct SocketIndex *ent2; SOCKET s2; s2 = set-&gt;fd_array[i] = set-&gt;fd_array[set-&gt;fd_count]; ent2 = pDispatcher-&gt;getSocketIndex( s2 ); if (!ent2) // This indicates a bug. return (0); if (read) ent2-&gt;read_pos_plus1 = i+1; else ent2-&gt;write_pos_plus1 = i+1; &#125; return (0);&#125;#define NEVENT 32void *win32_init(void *base)&#123; struct win32op *winop; size_t size; if (!(winop = (struct win32op*)malloc( sizeof(struct win32op)))) return NULL; winop-&gt;num_fds_in_fd_sets = NEVENT; size = FD_SET_ALLOC_SIZE(NEVENT); if (!(winop-&gt;readset_in = (struct win_fd_set *)malloc(size))) goto err; if (!(winop-&gt;writeset_in = (struct win_fd_set *)malloc(size))) goto err; if (!(winop-&gt;readset_out = (struct win_fd_set *)malloc(size))) goto err; if (!(winop-&gt;writeset_out = (struct win_fd_set *)malloc(size))) goto err; if (!(winop-&gt;exset_out = (struct win_fd_set *)malloc(size))) goto err; winop-&gt;readset_in-&gt;fd_count = winop-&gt;writeset_in-&gt;fd_count = 0; winop-&gt;readset_out-&gt;fd_count = winop-&gt;writeset_out-&gt;fd_count = winop-&gt;exset_out-&gt;fd_count = 0; winop-&gt;resize_out_sets = 0; return (winop);err: XFREE(winop-&gt;readset_in); XFREE(winop-&gt;writeset_in); XFREE(winop-&gt;readset_out); XFREE(winop-&gt;writeset_out); XFREE(winop-&gt;exset_out); XFREE(winop); return (NULL);&#125;intwin32_add(void *base, SOCKET fd, short old, short events, void *_idx)&#123; ModelManager* pDispatcher = (ModelManager*)base; struct win32op *winop = (struct win32op *)pDispatcher-&gt;getModelData(); struct SocketIndex *idx = (struct SocketIndex *)_idx; if (!(events &amp; (EV_READ|EV_WRITE))) return (0); //event_debug((\"%s: adding event for %d\", __func__, (int)fd)); if (events &amp; EV_READ) &#123; if (do_fd_set(winop, idx, fd, 1)&lt;0) return (-1); &#125; if (events &amp; EV_WRITE) &#123; if (do_fd_set(winop, idx, fd, 0)&lt;0) return (-1); &#125; return (0);&#125;intwin32_del(void *base, SOCKET fd, short old, short events, void *_idx)&#123; ModelManager* pDispatcher = (ModelManager*)base; struct win32op *winop = (struct win32op *)pDispatcher-&gt;getModelData(); struct SocketIndex *idx = (struct SocketIndex *)_idx; //event_debug((\"%s: Removing event for \"EV_SOCK_FMT,__func__, EV_SOCK_ARG(fd))); if ( (old &amp; EV_READ) &amp;&amp; !(events &amp; EV_READ) ) do_fd_clear(base, winop, idx, 1); if ( (old &amp; EV_WRITE) &amp;&amp; !(events &amp; EV_WRITE) ) do_fd_clear(base, winop, idx, 0); return 0;&#125;static voidfd_set_copy(struct win_fd_set *out, const struct win_fd_set *in)&#123; out-&gt;fd_count = in-&gt;fd_count; memcpy(out-&gt;fd_array, in-&gt;fd_array, in-&gt;fd_count * (sizeof(SOCKET)));&#125;/*static void dump_fd_set(struct win_fd_set *s)&#123;unsigned int i;printf(\"[ \");for(i=0;i&lt;s-&gt;fd_count;++i)printf(\"%d \",(int)s-&gt;fd_array[i]);printf(\"]\\n\");&#125;*/intwin32_dispatch(void *base, struct timeval *tv)&#123; ModelManager* pDispatcher = (ModelManager*)base; struct win32op *winop = (struct win32op *)pDispatcher-&gt;getModelData(); int res = 0; unsigned j, i; int fd_count; SOCKET s; if (winop-&gt;resize_out_sets) &#123; size_t size = FD_SET_ALLOC_SIZE(winop-&gt;num_fds_in_fd_sets); if (!(winop-&gt;readset_out = (struct win_fd_set *)realloc(winop-&gt;readset_out, size))) return (-1); if (!(winop-&gt;exset_out = (struct win_fd_set *)realloc(winop-&gt;exset_out, size))) return (-1); if (!(winop-&gt;writeset_out = (struct win_fd_set *)realloc(winop-&gt;writeset_out, size))) return (-1); winop-&gt;resize_out_sets = 0; &#125; fd_set_copy(winop-&gt;readset_out, winop-&gt;readset_in); fd_set_copy(winop-&gt;exset_out, winop-&gt;writeset_in); fd_set_copy(winop-&gt;writeset_out, winop-&gt;writeset_in); fd_count = (winop-&gt;readset_out-&gt;fd_count &gt; winop-&gt;writeset_out-&gt;fd_count) ? winop-&gt;readset_out-&gt;fd_count : winop-&gt;writeset_out-&gt;fd_count; if (!fd_count) &#123; Sleep(tv-&gt;tv_usec/1000); return (0); &#125; res = select(fd_count, (struct fd_set*)winop-&gt;readset_out, (struct fd_set*)winop-&gt;writeset_out, (struct fd_set*)winop-&gt;exset_out, tv); //event_debug((\"%s: select returned %d\", __func__, res)); if (res &lt;= 0) &#123; if( res == -1 ) &#123; printf(\"error:%d\\n\", getErrno() ); &#125; return res; &#125; if (winop-&gt;readset_out-&gt;fd_count) &#123; i = rand() % winop-&gt;readset_out-&gt;fd_count; for (j=0; j&lt;winop-&gt;readset_out-&gt;fd_count; ++j) &#123; if (++i &gt;= winop-&gt;readset_out-&gt;fd_count) i = 0; s = winop-&gt;readset_out-&gt;fd_array[i]; pDispatcher-&gt;insertActiveList( s, EV_READ); &#125; &#125; if (winop-&gt;exset_out-&gt;fd_count) &#123; i = rand() % winop-&gt;exset_out-&gt;fd_count; for (j=0; j&lt;winop-&gt;exset_out-&gt;fd_count; ++j) &#123; if (++i &gt;= winop-&gt;exset_out-&gt;fd_count) i = 0; s = winop-&gt;exset_out-&gt;fd_array[i]; pDispatcher-&gt;insertActiveList( s, EV_WRITE); &#125; &#125; if (winop-&gt;writeset_out-&gt;fd_count) &#123; SOCKET s; i = rand() % winop-&gt;writeset_out-&gt;fd_count; for (j=0; j&lt;winop-&gt;writeset_out-&gt;fd_count; ++j) &#123; if (++i &gt;= winop-&gt;writeset_out-&gt;fd_count) i = 0; s = winop-&gt;writeset_out-&gt;fd_array[i]; pDispatcher-&gt;insertActiveList( s, EV_WRITE); &#125; &#125; return (0);&#125;voidwin32_dealloc(void *base)&#123; ModelManager* pDispatcher = (ModelManager*)base; struct win32op *winop = (struct win32op *)pDispatcher-&gt;getModelData(); if (winop-&gt;readset_in) free(winop-&gt;readset_in); if (winop-&gt;writeset_in) free(winop-&gt;writeset_in); if (winop-&gt;readset_out) free(winop-&gt;readset_out); if (winop-&gt;writeset_out) free(winop-&gt;writeset_out); if (winop-&gt;exset_out) free(winop-&gt;exset_out); memset(winop, 0, sizeof(winop)); free(winop);&#125;#endif","categories":[{"name":"技术开发","slug":"tech","permalink":"http://www.limerence2017.com/categories/tech/"}],"tags":[{"name":"网络编程","slug":"网络编程","permalink":"http://www.limerence2017.com/tags/网络编程/"}]},{"title":"ECONNRESET和WSAECONNRESET怎么产生的以及如何避免","date":"2017-08-04T09:02:28.000Z","path":"2017/08/04/econreset/","text":"ECONNRESET是linux环境网络编程产生的错误，错误码为104， WSAECONNRESET是windows环境网络编程产生的错误，错误码为10054 两者产生的原因都一样，分以下几种情况： 1接收端recv或者read， 对端已经关闭连接，recv/read返回该错误 2 对端重启连接，还未建立连接 3 发送端已经断开连接，但是调用send会触发这个错误 第二点第三点都可以通过判断返回值解决，第一点在一些看似正常情况下也会触发该错误。比如对端close(fd)，接收端调用recv并没有返回0，而是-1，打印错误码为104或 10054，按道理讲这种情况按照返回值为0处理是可以的，但是尽量将代码写的规范一些，避免不必要的错误。 为什么close(fd)会导致接收端读到复位RST，也就是收到错误的104呢？ 因为close(fd)只是将文件描述符关闭，并没有关闭tcp建立起来的连接，断开连接需要四次握手，倘若发送端发送缓冲区有数据未发送完或者接受缓冲区有数据未读完，调用close(fd)，那么连接并没有关闭，这样，接收端收到的就是所谓的104或10054错误了。如何避免这个错误呢，就需要我们判断发送端发送和接受操作是否进行完，也就是判断缓冲区是否有数据，如果有数据需要等待数据处理完毕在关闭，否则会出现上述错误。 有一个做法是通过调用shutdown(s,SHUT_WR);关闭发送端的写端，这样发送端不发送数据，然后调用close这次会发送关闭连接的FIN标志，接收端接收到FIN，那么recv或者read返回的就是0. int shutdown(int sockfd,int how); Sockfd是需要关闭的socket的描述符。参数 how允许为shutdown操作选择以下几种方式： SHUT_RD：关闭连接的读端。也就是该套接字不再接受数据，任何当前在套接字接受缓冲区的数据将被丢弃。 进程将不能对该套接字发出任何读操作。 对 TCP套接字该调用之后接受到的任何数据将被确认然后无声的丢弃掉。 SHUT_WR:关闭连接的写端，进程不能在对此套接字发出写操作 SHUT_RDWR:相当于调用shutdown两次：首先是以SHUT_RD,然后以SHUT_WR 下面摘用网上的一段话来说明二者的区别：close—–关闭本进程的socket id，但链接还是开着的，用这个socket id的其它进程还能用这个链接，能读或写这个socket idshutdown–则破坏了socket 链接，读的时候可能侦探到EOF结束符，写的时候可能会收到一个SIGPIPE信号，这个信号可能直到socket buffer被填充了才收到。 close(sockfd);使用close中止一个连接，但它只是减少描述符的参考数，并不直接关闭连接，只有当描述符的参考数为0时才关闭连接。 而且shutdown只是处理连接关闭，并不能回收描述符，所以最终还是要调用close(fd)才能回收描述符，在所有描述符引用次数为0时发送 FIN消息给对端。 出了采取shutdown的方式，还可以通过设置socket属性，调用close时，检测在socket完成缓冲区读写后，才关闭连接 1234567struct linger &#123; int l_onoff; /* 0 = off, nozero = on */ int l_linger; /* linger time */ &#125;; 有下列三种情况：1、设置 l_onoff为0，则该选项关闭，l_linger的值被忽略，等于内核缺省情况，close调用会立即返回给调用者，如果可能将会传输任何未发送的数据； 2、设置 l_onoff为非0，l_linger为0，则套接口关闭时TCP夭折连接，TCP将丢弃保留在套接口发送缓冲区中的任何数据并发送一个RST给对方，而不是通常的四分组终止序列，这避免了TIME_WAIT状态； 3、设置 l_onoff 为非0，l_linger为非0，当套接口关闭时内核将拖延一段时间（由l_linger决定）。如果套接口缓冲区中仍残留数据，进程将处于睡眠状态，直 到（a）所有数据发送完且被对方确认，之后进行正常的终止序列（描述字访问计数为0）或（b）延迟时间到。 下面是代码：1234567891011int z; int s; struct linger so_linger; so_linger.l_onoff = 1 so_linger.l_linger = 30; z = setsockopt(s,SOL_SOCKET,SO_LINGER,&amp;so_linger, sizeof so_linger); if ( z ) perror(\"setsockopt(2)\"); close(s); 到目前为止，我觉得比较好的主动关闭方式是： 关闭端： 1确保发送缓存区没有数据未发送，调用shutdown(fd,SHUTWR); 2如果能接收到数据，继续接受，直到接收到对方的FIN，也就是 read返回0或者-1 3如果接收到关闭信号，那么调用close正常关闭。","categories":[{"name":"技术开发","slug":"tech","permalink":"http://www.limerence2017.com/categories/tech/"}],"tags":[{"name":"网络编程","slug":"网络编程","permalink":"http://www.limerence2017.com/tags/网络编程/"}]},{"title":"Udp打洞原理和源代码。","date":"2017-08-04T08:52:04.000Z","path":"2017/08/04/udphole/","text":"所谓udp打洞就是指客户端A通过udp协议向服务器发送数据包，服务器收到后，获取数据包，并且可获取客户端A地址和端口号。同样在客户端B发送给服务器udp数据包后，服务器同样在收到B发送过来的数据包后获取B的地址和端口号，将A和B的地址与端口号分别发送给对方，这样双方可以继续用UDP协议通信。这么做有什么用呢？因为对于一些应用或者需求，需要两个客户端临时做一些通信，而这种通信不需要建立tcp就可以完成，所以才去udp打洞。 下面附上测试代码： 头文件 123456789101112131415161718192021222324252627282930313233// udphole.cpp : 定义控制台应用程序的入口点。#ifdef WIN32#include \"stdafx.h\"#include &lt;winsock2.h&gt;#include &lt;stdio.h&gt;#pragma comment(lib, \"Ws2_32.lib\")typedef SOCKET socketfd;typedef SOCKADDR_IN sockaddr_in;#endif#ifdef __linux__ #include &lt;sys/types.h&gt; #include &lt;sys/socket.h&gt; #include &lt;netinet/in.h&gt; #include &lt;time.h&gt; #include &lt;string.h&gt; #include &lt;stdio.h&gt; #include &lt;unistd.h&gt; #include &lt;stdlib.h&gt; #include &lt;pthread.h&gt; #include &lt;iostream&gt; #include &lt;errno.h&gt; #include &lt;arpa/inet.h&gt; #include &lt;pthread.h&gt;typedef int socketfd;#endif#include &lt;list&gt;#include &lt;map&gt;#include &lt;iostream&gt;using namespace std; 服务器端核心代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140#include &lt;list&gt;#include &lt;map&gt;#include &lt;iostream&gt;using namespace std;int main(int argc, char* argv[])&#123; #ifdef WIN32 std::list&lt;SOCKADDR_IN&gt; addrList; WSADATA wsaData = &#123;0&#125;; if (0 != WSAStartup(MAKEWORD(2,2), &amp;wsaData)) &#123; printf (\"WSAStartup failed. errno=[%d]\\n\", WSAGetLastError()); return -1; &#125; #endif #ifdef __linux__ std::list&lt;sockaddr_in&gt; addrList; #endif //addrList 是地址列表，每次存放最新到来的。 socketfd sockServer = socket(AF_INET, SOCK_DGRAM, IPPROTO_UDP); if (-1 == sockServer) &#123; #ifdef WIN32 printf (\"socket server failed. errno=[%d]\\n\", WSAGetLastError()); #endif #ifdef __linx__ printf(\"socket server failed. errno=[%d]\\n\", errno); #endif return -2; &#125; sockaddr_in addrServer = &#123;0&#125;; addrServer.sin_family = AF_INET; addrServer.sin_addr.s_addr = INADDR_ANY;//inet_addr(\"192.168.1.2\"); addrServer.sin_port = htons(10000); if (0 != bind(sockServer, (sockaddr*)&amp;addrServer, sizeof(addrServer))) &#123; #ifdef WIN32 printf (\"bind server failed.errno=[%d]\\n\", WSAGetLastError()); #endif #ifdef __linux__ printf(\"bind server failed.errno=[%d]\\n\", errno); #endif return -3; &#125; cout &lt;&lt; \"okok6\"&lt;&lt;endl; while(1) &#123; char pcContent1[10240] = &#123;0&#125;; sockaddr_in addrUser1 = &#123;0&#125;; #ifdef WIN32 int nLen1 = sizeof(addrUser1); #endif #ifdef __linux__ socklen_t nLen1 = sizeof(addrUser1); #endif //服务器接收来自客户端的消息，并且用addrUser1保存地址和端口 if (-1 == recvfrom(sockServer, pcContent1, sizeof(pcContent1), 0, (sockaddr*)&amp;addrUser1, &amp;nLen1)) &#123; cout &lt;&lt; \"dfdfda\"&lt;&lt;endl; #ifdef WIN32 printf (\"recv user 1 failed.errno=[%d]\", WSAGetLastError()); #endif #ifdef __linux__ printf (\"recv user 1 failed.errno=[%d]\", errno); #endif return -4; &#125; else &#123; // printf (\"connect user ip=[%s] port=[%d]\\n\", inet_ntoa(addrUser1.sin_addr), htons(addrUser1.sin_port)); //如果地址列表非空，那么取出列表中的地址，并且与最新到来的客户端通信 if(addrList.size()) &#123; sockaddr_in peerAddr = addrList.front(); int nLen2 = sizeof(peerAddr); printf (\"peer user ip=[%s] port=[%d]\\n\", inet_ntoa(peerAddr.sin_addr), htons(peerAddr.sin_port)); if (-1 == sendto(sockServer, (char*)&amp;addrUser1, nLen1, 0, (sockaddr*)&amp;peerAddr, nLen2)) &#123; #ifdef WIN32 printf (\"send to peer user data failed.\\n\", WSAGetLastError()); #endif #ifdef __linux__ printf (\"send to peer user data failed.\\n\", errno); #endif return -6; &#125; if (-1 == sendto(sockServer, (char*)&amp;peerAddr, nLen2, 0, (sockaddr*)&amp;addrUser1, nLen1)) &#123; #ifdef WIN32 printf (\"send to connect user data failed.\\n\", WSAGetLastError()); #endif #ifdef __linux__ printf (\"send to connect user data failed.\\n\", errno); #endif return -6; &#125; addrList.pop_front(); &#125; else &#123; //如果列表为空，那么将该地址放入列表中。 addrList.push_back(addrUser1); &#125; &#125; &#125; #ifdef WIN32 Sleep(INFINITE); #endif #ifdef __linux__ //sleep(1000); #endif return 0;&#125; 下面是客户端发送消息的代码，比较简单。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667#include \"stdafx.h\"#include &lt;winsock2.h&gt;#include &lt;stdio.h&gt;#pragma comment(lib, \"Ws2_32.lib\")int _tmain(int argc, _TCHAR* argv[])&#123; WSADATA wsaData = &#123;0&#125;; if (0 != WSAStartup(MAKEWORD(2,2), &amp;wsaData)) &#123; printf (\"WSAStartup failed. errno=[%d]\\n\", WSAGetLastError()); return -1; &#125; SOCKET sockClient = socket(AF_INET, SOCK_DGRAM, IPPROTO_UDP); if (SOCKET_ERROR == sockClient) &#123; printf (\"socket server failed. errno=[%d]\\n\", WSAGetLastError()); return -2; &#125; char pcContent1[UCHAR_MAX] = &#123;0&#125;; SOCKADDR_IN addrServer = &#123;0&#125;; addrServer.sin_family = AF_INET; addrServer.sin_addr.s_addr = inet_addr(\"192.168.1.40\"); addrServer.sin_port = htons(10000); int nLen1 = sizeof(addrServer); //客户端发送自己的报文 if (SOCKET_ERROR == sendto(sockClient, pcContent1, 1, 0, (sockaddr*)&amp;addrServer, nLen1)) &#123; printf (\"recv user 1 failed.errno=[%d]\", WSAGetLastError()); return -3; &#125; SOCKADDR_IN addrUser = &#123;0&#125;; char pcContent2[UCHAR_MAX] = &#123;0&#125;; //阻塞接收来自服务器的消息。 if (SOCKET_ERROR == recvfrom(sockClient, pcContent2, sizeof(pcContent2), 0, (sockaddr*)&amp;addrServer, &amp;nLen1)) &#123; printf (\"recv user 1 failed.errno=[%d]\", WSAGetLastError()); return -5; &#125; else &#123; memcpy (&amp;addrUser, pcContent2, sizeof(addrUser)); sprintf (pcContent2, \"hello, user ip=[%s] port=[%d]\\n\", inet_ntoa(addrUser.sin_addr), htons(addrUser.sin_port)); //解析服务器消息后发送消息给另一个客户端。 if (SOCKET_ERROR == sendto(sockClient, pcContent2, strlen(pcContent2), 0, (sockaddr*)&amp;addrUser, nLen1)) &#123; printf (\"recv user 1 failed.errno=[%d]\", WSAGetLastError()); return -3; &#125; else &#123; //阻塞接收另一个客户端发送过来的消息 if (SOCKET_ERROR == recvfrom(sockClient, pcContent2, sizeof(pcContent2), 0, (sockaddr*)&amp;addrServer, &amp;nLen1)) &#123; printf (\"recv user 1 failed.errno=[%d]\", WSAGetLastError()); return -5; &#125; printf (\"%s\", pcContent2); &#125; &#125; Sleep(INFINITE); return 0;&#125; 效果如下，服务器收到来自客户端A和客户端B的报文后打印他们的信息，并且互相转发消息。客户端A和客户端B分别打印对方的地址和端口号到此为止，udp打洞的代码介绍完了。可以关注我的公众号，谢谢","categories":[{"name":"技术开发","slug":"tech","permalink":"http://www.limerence2017.com/categories/tech/"}],"tags":[{"name":"网络编程","slug":"网络编程","permalink":"http://www.limerence2017.com/tags/网络编程/"}]},{"title":"网络编程学习方法和图书推荐","date":"2017-08-04T08:38:00.000Z","path":"2017/08/04/networkbook/","text":"从事网络编程有五年多了，写过自己的Server，读过大部分网络库libevent，redis,muduo等等，市面上的网络用书大多读过，给新人一些建议，主要是从事服务器网络编程后端的同学。如果你没写过网络编程的代码，也没有这方面的知识，那么该如何下手呢？这个时候不需要盲目看书，先培养一下自己的兴趣，了解TCP如何建立连接，TCP三次握手和四次握手的过程，有了这个，然后去了解socket方面编程的基本知识，socket的创建，绑定，连接，发送，接收，建立连接等api，学习完这些api，试着去写一个单线程阻塞通信 demo，客户端发送数据，服务器接收数据，然后将数据返回给客户端，客户端收到后继续发送，这样简单的echo服务器就写出来了。 这是我做的一个小demo，可以参考下，但是不是echo，读者可自己改为echo服务器。 http://www.cnblogs.com/secondtonone1/p/5460942.html 如果很多个客户端连接过来怎么处理呢？这时需要了解多线程模式的网络编程，你可以去了解accept原理，和线程创建处理新的连接。这样就可以做出一个多线程echo的Server了。这是我做的一个简单的accept多线程服务器，读者可自己改为echo模式 http://www.cnblogs.com/secondtonone1/p/5461120.html 有了这些基础知识，你就可以深入了解网络变成了，下一步要做的是了解TCP的socket缓存原理，阻塞原理，非阻塞的socket如何返回错误码，错误码的意义和如何处理，这些知识是你学习非阻塞多路复用的基础，学完这些，可以学多路复用的几种模型了，select，poll，epoll，iocp，kqueue等等，学的时候去补充自己不知道的一些TCP知识。多路复用学习后可以简单的去写一些多路复用服务器demo。 这是我之前讲过的epoll知识和自己写的epoll demo http://www.cnblogs.com/secondtonone1/p/5367495.html http://www.cnblogs.com/secondtonone1/p/5432453.html 会写多路复用服务器就可以了吗？这只是开始，下面就要阅读源码和高性能的框架了，我推荐去读一读redis和libevent这两个框架，对网络编程提升很大，其中的缓存思想也很重要。这个时候你需要的是从框架的角度搭建一个高性能的服务器，需要了解事件堆，Reactor模式，Proactor模式，将不同的多路复用封装为一个IOService，就像libevent的EventLoop，像boost asio的ioservice一样。 下面是我封装的一个服务器，上传到github了 https://github.com/secondtonone1/betternet 这些都会了，也就是我现在的水平了，我现在在看一些网络大神的思想和视频，从他们的设计角度感受如何架构一个优秀的框架，建议大家看看陈硕的muduo网络库和编程视频，能醍醐灌顶。我现在也在学一些其他的框架，主要是想触类旁通，同时看看优秀的框架代码，虽然自己写不出太优秀的框架，至少可以开阔眼界，作为积累。 下面是推荐大家的网络图书： 我推荐新手先看 Linux程序设计(第4版)Linux高性能服务器编程看过之后再看Richard的三本网络书这些都看过之后，需要实战，实战过程中可以看看以及陈硕的经验之谈，我现在在看的 这些都看过了，可以看看源码 libevent 源码下载地址：http://libevent.org/ redis源码下载地址：http://www.redis.cn/download.html boost asio 文档和下载：http://www.boost.org/doc/libs/1_63_0/doc/html/boost_asio.html muduo网络库：http://code.csdn.net/openkb/p-muduo 这些源码都搞通了，就有了自己的方法和框架了，然后就自己闯荡吧。","categories":[{"name":"技术开发","slug":"tech","permalink":"http://www.limerence2017.com/categories/tech/"}],"tags":[{"name":"网络编程","slug":"网络编程","permalink":"http://www.limerence2017.com/tags/网络编程/"}]},{"title":"redis 配置和使用(C++)","date":"2017-08-04T08:17:47.000Z","path":"2017/08/04/redisset/","text":"一、Redis简介：Redis为非关系型数据库，Redis是一个Key-Value存储系统。它支持存储的value类型有：string(字符串),list(链表), set(无序集合),zset(sorted set有序集合)和hash，Redis支持各种不同方式的排序。数据都是缓存在内存中的，它也可以周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并实现了master-slave(主从)同步。 二、Redis安装和使用：Redis下载地址，我下载的为最新版本： wget http://download.redis.io/releases/redis-3.2.8.tar.gz 解压安装： 123$ tar xzf redis-3.2.8.tar.gz$ cd redis-3.2.8$ make make完后 redis-3.2.8目录下会出现redis-server和redis-cli下面在src目录下启动redis服务.1$./redis-server 注意这种方式启动redis 使用的是默认配置。也可以通过启动参数告诉redis使用指定配置文件使用下面命令启动.1$ ./redis-server redis.conf redis.conf是一个默认的配置文件。我们可以根据需要使用自己的配置文件。启动redis服务进程后，就可以使用测试客户端程序redis-cli和redis服务交互了.下面为官方提供的案例：服务器启动：1src/redis-server redis.conf 客户端读写： 12345$ src/redis-cliredis&gt; set foo barOKredis&gt; get foo\"bar\" redis.conf 为redis配置文件，有很多参数供用户修改，这里仅仅说明几个参数，其他的读者自行搜索。 port: 为redis启动的端口号，当需要启动多个redis服务器时修改该参数，可以启动多个服务。 bind ：绑定ip，设置后只接受自该ip的请求 databases ：设置数据库的个数，默认使用的数据库为0，redis有16个数据库，修改参数可写入不同的数据库。 requirepass ：设置登录时需要使用的密码。 下面修改requirepass 为 zjml123456&amp;&amp;REDIS,那么重启redis-server,放在后台运行。效果就是这样然后启动客户端使用密码登录并且查询数据使用密码命令为：auth 密码 设置key和value的命令为: set key value 取出key对应的value 为： get key 使用C++访问redis:使用redis接口之前需要将hireids.h 和libhiredis.a放到项目目录里，这两个文件在redis解压目录redis-3.2.8/deps/下,我这里写了一个demo，所以都放在demo的文件夹下了。 下面介绍redis提供的供C++访问的接口 主要包括如下四个方法 redisContext redisConnect(const char ip, int port) 该函数用来连接redis数据库， 两个参数分别是redis数据库的ip和端口，端口号一般为6379。 void redisCommand(redisContext c, const char *format…) 该函数用于执行redis数据库中的命令，第一个参数为连接数据库返回的redisContext，剩下的参数为变参，如同C语言中的prinf()函数。此函数的返回值为void*，但是一般会强制转换为redisReply类型，以便做进一步的处理。根据redisReply中的type变量类型判断命令执行情况 REDIS_REPLY_STATUS： 返回执行结果为状态的命令。比如set命令的返回值的类型是REDIS_REPLY_STATUS，然后只有当返回信息是”OK”时，才表示该命令执行成功。 可以通过reply-&gt;str得到文字信息，通过reply-&gt;len得到信息长度。 REDIS_REPLY_ERROR： 返回错误。错误信息可以通过reply-&gt;str得到文字信息，通过reply-&gt;len得到信息长度。 REDIS_REPLY_INTEGER： 返回整型标识。可以通过reply-&gt;integer变量得到类型为long long的值。 REDIS_REPLY_NIL: 返回nil对象，说明不存在要访问的数据。 REDIS_REPLY_STRING: 返回字符串标识。可以通过reply-&gt;str得到具体值，通过reply-&gt;len得到信息长度。 REDIS_REPLY_ARRAY: 返回数据集标识。数据集中元素的数目可以通过reply-&gt;elements获得，每个元素是个redisReply对象， 元素值可以通过reply-&gt;element[..index..].*形式获得，用在获取多个数据结果的操作。 void freeReplyObject(void *reply) 释放redisCommand执行后返回的的redisReply所占用的内存。 void redisFree(redisContext *c) 释放redisConnect()所产生的连接。 下面是我封装的一个C++访问redis的类 RedisManager.h 12345678910111213141516171819202122class RedisManager &#123; public: RedisManager(); virtual ~RedisManager(); //初始化函数 bool initial(); //释放函数 void release(); //封装的set接口 void set(std::string key, std::string value); //封装的get接口 std::string get(std::string key); private: //连接的缓存指针 redisContext* m_pConnect; //请求处理结果指针 redisReply* m_pReply; &#125;; RedisManager.cpp 分别介绍几个接口： 构造函数和析构函数没写代码，下面是初始化函数： 初始化函数： 123456789101112131415161718192021222324252627282930313233343536373839bool RedisManager::initial()&#123; //redis服务器ip const char* redisIp = \"192.168.1.40\"; //redis服务器端口 int redisPort = 6379; //连接redis服务器 m_pConnect = redisConnect(redisIp, redisPort); m_pReply = NULL; if(!m_pConnect) &#123; return false; &#125; if (m_pConnect != NULL &amp;&amp; m_pConnect-&gt;err) &#123; cout &lt;&lt; \" redis connect failed!!!!\" &lt;&lt; endl; return false; &#125; //根据密码登录 m_pReply =(redisReply*) redisCommand(m_pConnect, \"AUTH %s\", mypass.c_str()); if(!m_pReply) &#123; cout &lt;&lt; \"redis exe failed!!\"&lt;&lt;endl; return false; &#125; if( !(m_pReply-&gt;type == REDIS_REPLY_STATUS &amp;&amp; strcasecmp(m_pReply-&gt;str,\"OK\")==0)) &#123; cout &lt;&lt; \" redis auth failed!!!!\" &lt;&lt; endl; freeReplyObject(m_pReply ); m_pReply = NULL; return false; &#125; freeReplyObject(this-&gt;m_pReply ); m_pReply = NULL; cout &lt;&lt; \" redis auth success!!!!\" &lt;&lt; endl; return true;&#125; 释放函数：1234567void RedisManager::release()&#123; //释放连接 freeReplyObject(m_pConnect); m_pConnect = NULL; m_pReply = NULL;&#125; set函数： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849void RedisManager::set(std::string key, std::string value)&#123; //设置key和value关系，插入redis redisReply* r =(redisReply*)redisCommand(this-&gt;m_pConnect, \"SET %s %s\", key.c_str(), value.c_str()); if(!r) &#123; cout &lt;&lt; \"set redis faliled\" &lt;&lt; endl; return; &#125; //执行失败 if( !(r-&gt;type == REDIS_REPLY_STATUS &amp;&amp; strcasecmp(r-&gt;str,\"OK\")==0)) &#123; cout &lt;&lt; \"set redis faliled\" &lt;&lt; endl; freeReplyObject(r ); return; &#125; cout &lt;&lt; \"set redis success\"&lt;&lt;endl; freeReplyObject(r );&#125;``` get函数：``` cppstd::string RedisManager::get(std::string key)&#123; //根据key获取value m_pReply = (redisReply*)redisCommand(this-&gt;m_pConnect, \"GET %s\", key.c_str()); if(!m_pReply) &#123; cout &lt;&lt; \"get value failed\" &lt;&lt; endl; return \"\"; &#125; //get成功返回结果为 REDIS_REPLY_STRING if( m_pReply-&gt;type != REDIS_REPLY_STRING ) &#123; cout &lt;&lt; \"get redis faliled\" &lt;&lt; endl; freeReplyObject(m_pReply ); m_pReply = NULL; return \"\"; &#125; cout &lt;&lt; \"get redis success\"&lt;&lt;endl; std::string valuestr = m_pReply-&gt;str; freeReplyObject(m_pReply ); m_pReply = NULL; return valuestr ;&#125; main 函数为：123456789101112131415161718int main()&#123; RedisManager * redisManager = new RedisManager(); if(redisManager) &#123; redisManager-&gt;initial(); edisManager-&gt;set(\"test\",\"nice to meet u!\"); std::string valueStr = redisManager-&gt;get(\"1sdfd\"); cout &lt;&lt; valueStr &lt;&lt; endl; redisManager-&gt;release(); delete redisManager; &#125; &#125; 源码下载地址： http://download.csdn.net/detail/secondtonone1/9826761","categories":[{"name":"技术开发","slug":"tech","permalink":"http://www.limerence2017.com/categories/tech/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://www.limerence2017.com/tags/C/"},{"name":"网络编程","slug":"网络编程","permalink":"http://www.limerence2017.com/tags/网络编程/"},{"name":"Linux环境编程","slug":"Linux环境编程","permalink":"http://www.limerence2017.com/tags/Linux环境编程/"}]},{"title":"大并发服务器框架设计","date":"2017-08-04T07:38:23.000Z","path":"2017/08/04/ioservertype/","text":"简单谈一谈大并发服务器框架设计的基本思路基本的服务器框架都是C/S结构的，请求和相应流程是这样的：这样的框架存在一个很严重的问题，当客户端大并发请求到来，服务器需要进行大量的数据库操作，假设数据库最大连接数为1000个，此时有10000个请求访问应用服务器，那么应用服务器只能处理1000个请求，剩下99000个等待1000个请求处理好后再进行访问数据库处理。可以在应用服务器和数据库服务器中间增加中间层DAL，DAL采用缓冲队列和连接池设计。DAL设计缓冲队列，存储等待的请求，并且DAL中设计数据库连接池，当数据库连接池中有空闲连接，那么从缓冲队列中取出一个请求处理，以此类推。这种做法有效的降低了服务器的压力，但是没有提高处理速度，仅仅保证了请求被缓存，处理效率仍受限于数据库的并发数。那么可以再增加一层缓存，将常用的数据加载如缓存，有请求到来时，应用服务器先从缓存中获取数据，如果缓存中有数据，那么不需要访问数据库，如果缓存中没有，在访问数据库取出数据，并更新缓存。缓存如何同步？ 有两种手段： 第一种方法： 缓存是具有时效的，在一定时间过后会超时timeout，如果缓存失效，那么重新去数据库查询，查询后更新缓存，这种方法不是实时的，实时性比较差。 第二种方法：当有请求修改数据时，更新缓存，并且将要修改的数据投入DAL层，当数据库有空闲连接时，再持久化存盘。 缓存的不足之处： 当缓存足够多时，需要将不活跃缓存数据换出内存，叫做缓存换页。缓存换出算法和操作系统换页算法类似，FIFO，LRU（least recently used），LFU（least frequently used）等。实际缓存的实现不需要自己去实现，有很多开源技术，nosql技术就是非关系型数据库的意思。非关系型数据库如redis，memcatched等。缓存可以跟应用服务器部署在同一台机器上，也可以部署在单独机器上。我推荐将缓存服务器部署在单独机器上，假设有两台应用服务器，如果将缓存部署在不同的应用服务器上，那么不同的应用服务器很难访问彼此的缓存，非常不方便。将缓存部署在单独服务器上，各个应用服务器都能访问该缓存服务器。如果有大量的业务请求到来，虽然设计了多个应用服务器，也架设了缓存服务器，完善了中间层的缓冲队列和数据库连接池，但是数据库服务器仍然会出现瓶颈。比如当有大量复杂的写操作数据库，很多读数据库的操作就被阻塞了，为解决这个问题可将数据库实现读写分离。由于数据库读操作会比写操作多，那么可以对数据库执行负载均衡。主流数据库都有replication机制，采用replication机制可以实现负载均衡。中间层的写数据库操作投递到master数据库中，读操作从slave数据库中读取，当master数据库中数据被修改后，数据库采用replication机制将数据同步给slave服务器。同样的道理，应用服务器也可以实现负载均衡，架设多个应用服务器，不同的请求分配给不同的应用服务器。可单独设计一个任务服务器监控各个应用服务器的负载情况，合理的分配任务给各个应用服务器。这种方式是任务服务器主动地分配任务给应用服务器，应用服务器被动的接受任务，这种方式在任务请求类型相近的情况下，分配方式非常合理。但是假设应用服务器A接受了3个任务，应用服务器B接受了5个任务，按照负载均衡的权重法或最小连接法，肯定会分配给A任务，但是如果这3个任务都是复杂的写操作，而B的5个任务都是简单的读操作，那么这就存在分配的不合理性，如何解决这个问题呢？可以换一种思路去解决这个问题，让应用服务器主动去请求任务服务器，主动获取任务处理，如果应用服务器处于忙碌状态就不需要请求新的任务，空闲的应用服务器会去请求任务服务器中的任务，这是最合理的负载均衡。如果所有应用服务器都处于忙碌状态，那么任务服务器将任务缓存至自己的任务队列，当应用服务器空闲时会来取任务。考虑这样一个问题，如果任务服务器出现故障怎么办？任务服务器需要有多台，并且实现failover机制，多台任务服务器之间实现心跳，如果检测不到对方心跳，则使自己成为主任务服务器。到目前为止，这个框架可以适用于大部分服务器逻辑。为保证数据库的响应速度和处理效率，可以对数据库进行分区。 数据库分区有两种形式(分库、分表) 分库：数据库可以按照一定的逻辑把表分散到不同的数据库。这叫做垂直分区，就是所每个库的表不同，功能不同。这样做不常见，因为很大情况下，数据库中各个表是关联的， 如果将不同的表分配到不同的数据库中，会存在很多不便。 分表：将一个表的不同数据分配到各个数据库，这样每个数据库的表结构是一样的，只是存储的用户数据不同而已，叫做水平分区。分表的方式很常见，如果数据库的压力增加， 我们就采取分表的方式减少数据库的压力。 另外服务器开发的几个性能杀手： 1 数据拷贝，数据从内核态copy到用户态，或者在用户态之间copy会造成性能损失，尽量采用缓存的方式解决。 2 环境切换 ，多线程上下文切换造成开销。如果服务器是单核的，那么采用状态机方式单线程效果最佳。如果是多核的， 合理采用多线程，可以提升性能。 3 内存分配，可以采用内存池，提前分配。 4 锁竞争，加锁解锁会造成一定的效率衰减。","categories":[{"name":"技术开发","slug":"tech","permalink":"http://www.limerence2017.com/categories/tech/"}],"tags":[{"name":"网络编程","slug":"网络编程","permalink":"http://www.limerence2017.com/tags/网络编程/"}]},{"title":"TCP/IP地址格式转换API","date":"2017-08-04T07:30:02.000Z","path":"2017/08/04/tcpapi/","text":"1、htonl ()和ntohl( ) ntohl( )—–网络顺序转换成主机顺序(长整型) u_long PASCAL FAR ntohl (u_long netlong); htonl ()—–主机顺序转换成网络顺序 (长整型) u_long PASCAL FAR htonl (u_long hostlong); 2、htons ()和ntohs( ) htons()——主机顺序转换成网络顺序(短整型) u_short PASCAL FAR htons (u_short hostshort); ntohs()——网络顺序转换成主机顺序(短整型) u_short PASCAL FAR ntohs (u_short netshort); 3、inet_addr( )和inet_ntoa ( ) unsigned long PASCAL FAR inet_addr (const char FAR * cp); char FAR * PASCAL FAR inet_ntoa (struct in_addr in); inet_addr函数需要一个字符串作为其参数，该字符串指定了以点分十进制格式表示的IP地址（例如：192.168.1.161）。而且inet_addr函数会返回一个适合分配给S_addr的u_long类型的数值。 1234567891011int sockfd; struct sockaddr_in my_addr; sockfd = socket(AF_INET, SOCK_STREAM, 0); my_addr.sin_family = AF_INET; /* 主机字节序 */ my_addr.sin_port = htons(9925); /* short, 网络字节序 */ my_addr.sin_addr.s_addr = inet_addr(\"192.168.0.1\"); bzero(&amp;(my_addr.sin_zero), 8); bind(sockfd, (struct sockaddr *)&amp;my_addr, sizeof(struct sockaddr)); inet_ntoa函数会完成相反的转换，它接受一个in_addr结构体类型的参数并返回一个以点分十进制格式表示的IP地址字符串。 服务器accept收到一个连接后，可以通过inet_ntoa找到对方ip，输出为字符串格式的点分十进制 123456789client = accept(serverSocket, (struct sockaddr *)&amp;clientAddr, (socklen_t *)&amp;addr_len); if (client &lt; 0) &#123; perror(\"accept\"); &#125; printf(\"\\nRecv client data...\\n\"); printf(\"IP is %s\\n\", inet_ntoa(clientAddr.sin_addr)); sockaddr_in , sockaddr , in_addr区别1234struct sockaddr &#123; unsigned short sa_family; char sa_data[14]; &#125;; 上面是通用的socket地址，具体到Internet socket，用下面的结构，二者可以进行类型转换123456struct sockaddr_in &#123; short int sin_family; unsigned short int sin_port; struct in_addr sin_addr; unsigned char sin_zero[8]; &#125;; struct in_addr就是32位IP地址。123456789struct in_addr &#123; union &#123; struct &#123; u_char s_b1,s_b2,s_b3,s_b4; &#125; S_un_b; struct &#123; u_short s_w1,s_w2; &#125; S_un_w; u_long S_addr; &#125; S_un; #define s_addr S_un.S_addr &#125;; inet_addr()是将一个点分制的IP地址(如192.168.0.1)转换为上述结构中需要的32位IP地址(0xC0A80001)。 填值的时候使用sockaddr_in结构，而作为函数（如socket, listen, bind等）的参数传入的时候转换成sockaddr结构就行了，毕竟都是16个字符长。 名词解析： 主机字节序： 不同的CPU有不同的字节序类型，这些字节序是指整数在内存中保存的顺序，这个叫做主机序。最常见的有两种 1．Little endian：低字节存高地址，高字节存低地址 2．Big endian：低字节存低地址，高字节存高地址 网络字节序： 网络字节顺序是TCP/IP中规定好的一种数据表示格式，它与具体的CPU类型、操作系统等无关，从而可以保证数据在不同主机之间传输时能够被正确解释。网络字节顺序采用big endian排序方式。 为了进行转换bsd socket提供了转换的函数，有下面四个网络与主机字节转换函数:htons ntohs htonl ntohl (s 就是short l是long h是host n是network) htons 把unsigned short类型从主机序转换到网络序，htonl 把unsigned long类型从主机序转换到网络序，ntohs 把unsigned short类型从网络序转换到主机序，ntohl 把unsigned long类型从网络序转换到主机序。 在使用little endian的系统中 这些函数会把字节序进行转换 在使用big endian类型的系统中这些函数会定义成空宏","categories":[{"name":"技术开发","slug":"tech","permalink":"http://www.limerence2017.com/categories/tech/"}],"tags":[{"name":"网络编程","slug":"网络编程","permalink":"http://www.limerence2017.com/tags/网络编程/"}]},{"title":"柔性数组探索和应用","date":"2017-08-04T04:48:23.000Z","path":"2017/08/04/avilablearray/","text":"redis字符串可以实现通过地址偏移找到所在结构体的首地址，struct sdshdr *sh = (void *)(s - (sizeof(struct sdshdr)))也就是通过buf地址可以找到sdshdr的地址，这个我一直不理解，写了代码测试下地址一次间隔4，结构体总大小为8，最后一个buf是空数组，没大小。之前自己一直错误的认为buf的大小按照char 开辟，这次打印出来大小为0将结构体buf成员改为char 类型这次大小变为12了，也就是char* 占用了四个字节 现在回到最初的结构 我尝试给buf开辟空间编译是不允许的，这是个零大小的数组，但是buf[lenth]这种方式可以访问，只是数组越界罢了。那就要一次给这个结构体开辟好空间，通过buf位移取出数据结果 &amp;buf和buf所指向的地址一个地址。因为它本身没有空间","categories":[{"name":"技术开发","slug":"tech","permalink":"http://www.limerence2017.com/categories/tech/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://www.limerence2017.com/tags/C/"}]},{"title":"弱点针对训练（函数指针）","date":"2017-08-04T04:40:26.000Z","path":"2017/08/04/weakeness/","text":"想着把每一个基础的知识点搞清，趁着早晨凉快就先写一些总结函数指针，基本结构是 函数返回类型（* 函数指针名字）（函数参数1，函数参数2，...）；这种指针用于指向一个函数的地址，可以通过函数指针回调同类型的不同函数，实现类似于事件回调机制的功能。先写一个简单的测试程序编译后看看有什么结果pFunc1和pFunc2是没问题的，pFunc3 提示两个函数指针类型不匹配，因为pFunc3是 int（*）(int , int);pFunc4 其实是一个函数类型的对象，不予许赋值的。所以进行如下更改，并写出测试代码对于函数指针赋值的时候，可以直接用函数名字，也可以进行&amp;函数名赋值，综上所述，可以先定义一个函数类型typedef 函数返回类型 函数名 （函数形参1， 函数形参2，…）;之后用 函数名 函数指针;也可以 typedef 函数返回类型 (*函数指针类型名) （函数形参1，函数形参2,…）；之后用 函数指针类型名 函数指针；","categories":[{"name":"技术开发","slug":"tech","permalink":"http://www.limerence2017.com/categories/tech/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://www.limerence2017.com/tags/C/"}]},{"title":"stringstream使用方法","date":"2017-08-04T04:36:06.000Z","path":"2017/08/04/stringstream/","text":"C++ 有stringstream这个工具可以方便的进行数据类型的转换 使用时包含 #include &lt;sstream.h&gt; using namespace std; 当需要将一个整形的数转换为字符串 123456789stringstream mystream;int a = 100;mystream &lt;&lt; a;std::string numstr;mystream &gt;&gt; mumstr; 如果需要将一个字符串转化为整形数 再次使用mystream需要清除之前的状态位 调用 mystream.clear(); 并且字符串置空 mystream.str(“”); 这样就可以使用了。 1234567mystream.clear()mystream.str(\"\");string strtest = \"1234\";mystream &lt;&lt; strtest;int numconvert;mystream &gt;&gt; numconvert; 除此之外 stringstream可以连续将输入的内容输出到指定变量 123456789std::string str1 = \"1221\";std::string str2 = \"12.34\";std::string str3 = \"899\";std::stringstream mystream;mystream &lt;&lt; str1 &lt;&lt; str2 &lt;&lt; str3;int num1, num3;double num2;mystream &gt;&gt; num1 &gt;&gt; num2 &gt;&gt; num3; 大体上就是mystream常用的用法了。","categories":[{"name":"技术开发","slug":"tech","permalink":"http://www.limerence2017.com/categories/tech/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://www.limerence2017.com/tags/C/"}]},{"title":"大根堆的原理与实现。","date":"2017-08-04T04:23:28.000Z","path":"2017/08/04/bigheap/","text":"大根堆的定义：1 大根堆是一个大根树2 大根堆是一个完全二叉树所以大根堆用数组表示是连续的，不会出现空白字段。 对于大根堆的插入对于大根堆的插入，可以在排序前确定大根堆的形状，可以确定元素5从位置6插入，那么比较元素5和位置3的元素2， 元素5比元素2大，将2下移。接着比较元素5和元素20，一次类推，直到找到元素5的合理位置。 接着看一下如果插入的元素是21，怎么进行排序。21比2大，所以将2下移，接着比较21和20，发现20比21小，20下移，最终21放到 根的位置。形成大根堆。 对于大根堆的删除大根堆删除根元素，那么可以确定删除后的形状。可以理解成将最后一个叶子节点放在 合理位置，首先比较叶子节点元素10和根节点的两个孩子15和2，选出两个节点中最大的 元素15,15比10大，所以15进行气泡。放到根节点。然后15所在的位置2,变为不确定的问号。 由于14比10大，那么14起泡放到位置2，根据大根堆的形状，最后将10放到左节点 将一个无序的完全二叉树变为大根堆将一个无序的完全二叉树变为大根堆(或者小根堆)，首先要找到最有一个叶子节点的父节点， 对该父节点为根节点的子树进行排序，生成一个大根堆(小根堆)。然后从节点位置依次 向前做同样的排序，将该节点到根节点的所有子树变为大根堆(小根堆)举例子：如上图所示，因为总共有6个节点，6/2 = 3,所以元素19的父节点是位置3的元素4， 将以4位根的子树变为大根堆。因为19比4大，所以19上移，4做叶子节点。依次类推， 从位置3到位置1的所有子树都按照这种逻辑处理，最终变成大根堆。 接着要处理位置2的子树，位置2的元素为1，两个节点为25和12，选最大的元素25，因为 25比1大，所以25进行上移，1变为叶子节点。这样位置2的子树就处理完了。 接着处理位置1，因为位置1的元素为6，两个节点分别为25和19，取最大节点元素25， 因为25比6大，所以25上移，而此时位置2还有两个节点元素1和元素12，需要比较元素6 和这两个节点中最大的，以确定大根堆。由于12比6大，所以12上移，6变为叶子节点。 最终用数组表示这个大根堆就是[25,12,19,1,6,4] 下面是代码实现和测试：大根堆的类结构：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647template &lt;class T&gt;class maxHeap&#123;public: maxHeap(void) &#123; m_nHeapSize = 0; m_nHeapCapacity = 0; m_pHeapArray = NULL; &#125; maxHeap(const maxHeap&amp; tempHeap); maxHeap(T * heapArray, int arrayLen); ~maxHeap()&#123; if(m_pHeapArray) &#123; free(m_pHeapArray); &#125; m_pHeapArray = NULL; m_nHeapSize = 0; m_nHeapCapacity = 0; &#125; //插入节点 void insertNode(const T&amp; t); //pop堆顶元素 const T&amp; popRoot(); //打印自己的堆元素，用数组表示法输出 void printHeap(); //将一个无序的数组变为大根堆 void createMaxHeap(T * heapArray, int arrayLen); //销毁自己的堆元素 void deallocMaxHeap(); //打印数组的元素 void printHeap(T * heapArray, int arrayLen);private: //堆的数组元素，连续区间首地址 T* m_pHeapArray; //当前使用的大小 int m_nHeapSize; //堆的容量，实际开辟的大小 int m_nHeapCapacity;&#125;; 两个构造函数：1234567891011121314template &lt;class T&gt;maxHeap&lt;T&gt;::maxHeap(const maxHeap &amp;tempHeap)&#123; m_nHeapSize = tempHeap.m_nHeapSize; m_pHeapArray = malloc(sizeof(class maxHeap) *m_nHeapSize); m_nHeapCapacity = m_nHeapSize;&#125;template &lt;class T&gt;maxHeap&lt;T&gt;::maxHeap(T * heapArray, int arrayLen)&#123; m_nHeapSize = arrayLen; m_pHeapArray = malloc(sizeof(class maxHeap) * m_nHeapSize); m_nHeapCapacity = arrayLen;&#125; 插入节点1234567891011121314151617181920212223242526272829303132333435363738template &lt;class T&gt;void maxHeap&lt;T&gt;::insertNode(const T&amp; node)&#123; m_nHeapSize ++; if(m_nHeapSize &gt;= m_nHeapCapacity) &#123; m_pHeapArray = (T *)realloc(m_pHeapArray, sizeof(T) * m_nHeapSize *2); &#125; m_nHeapCapacity = m_nHeapSize*2; //当前节点所在位置 int currentIndex = m_nHeapSize; //该节点父节点所在位置 int parentIndex = currentIndex/2; //当前节点为根节点，跳出循环直接插入即可 while(currentIndex != 1) &#123; //父节点元素小于该node，因为是大根堆，所以父节点下移 if(m_pHeapArray[parentIndex -1] &lt; node) &#123; //父节点数据下移 m_pHeapArray[currentIndex - 1] = m_pHeapArray[parentIndex -1]; //更新当前节点位置，当前比较位置上移 currentIndex = currentIndex/2; //父节点位置同样上移 parentIndex = parentIndex/2; &#125; else &#123; break; &#125; &#125; //因为节点数是从1开始的，所以节点数-1表示数组中的位置 m_pHeapArray[currentIndex -1] = node; &#125; 打印元素123456789101112131415161718192021template &lt;class T&gt;void maxHeap&lt;T&gt;::printHeap()&#123; cout &lt;&lt;\"current max heap array is :\" &lt;&lt; endl; for(int i = 0; i &lt; m_nHeapSize; i++) &#123; cout &lt;&lt; m_pHeapArray[i] &lt;&lt; \" \"; &#125; cout &lt;&lt; endl;&#125;template &lt;class T&gt;void maxHeap&lt;T&gt;::printHeap(T * heapArray, int arrayLen)&#123; cout &lt;&lt;\"current max heap array is :\" &lt;&lt; endl; for(int i = 0; i &lt; arrayLen; i++) &#123; cout &lt;&lt; heapArray[i] &lt;&lt; \" \"; &#125; cout &lt;&lt; endl;&#125; pop堆顶的元素，取出最大值1234567891011121314151617181920212223242526272829303132333435363738394041template &lt;class T&gt;const T&amp; maxHeap&lt;T&gt;::popRoot()&#123; //先取出最后的叶子节点 const T&amp; lastEle = m_pHeapArray[m_nHeapSize-1]; //更新heapsize m_nHeapSize --; //删除时需要从根节点开始，找到最大值起泡 int currentIndex= 1; //当前节点的做孩子 int leftChild = currentIndex *2; //当前节点的孩子节点超过堆大小，说明该节点为叶子节点 while(leftChild &lt;= m_nHeapSize) &#123; int bigChild = leftChild; //取出两个孩子中大的孩子，然后将大的孩子节点数据上移 if(leftChild &lt; m_nHeapSize &amp;&amp; m_pHeapArray[leftChild-1] &lt; m_pHeapArray[leftChild]) &#123; //更新大孩子节点为右节点 bigChild = leftChild +1; &#125; //比较两个节点中大的孩子节点和取出的最后叶子节点，那个数值大 //如果最后的叶子节点数值大，那么可以跳出循环,因为找到了lastEle的合理位置 //剩余的树也是大根堆 if(m_pHeapArray[bigChild -1] &lt;= lastEle) &#123; break; &#125; //大节点数据上移 m_pHeapArray[currentIndex -1] = m_pHeapArray[bigChild-1]; //更新插入位置为当前大节点位置 currentIndex = bigChild; leftChild = currentIndex *2; &#125; m_pHeapArray[currentIndex-1] = lastEle; return lastEle;&#125; 将一个无序的数组元素，变为大根堆1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950template &lt;class T&gt;void maxHeap&lt;T&gt;::createMaxHeap(T * heapArray, int arrayLen)&#123; //判断异常 if(arrayLen &lt;= 0 || heapArray == NULL) &#123; return ; &#125; //从最后一个叶子节点的父节点开始，依次从该位置到根节点 //例如该位置为3，那么位置3，位置2，位置1的根节点的子树依次处理为大根堆 int currentIndex = arrayLen; //父节点位置 int beginIndex = currentIndex/2; //依次处理，形成子树大根堆 for(int i = beginIndex; i &gt; 0; i--) &#123; int rootEle = heapArray[i-1]; int curNode = i; int leftChild = i *2; while(leftChild &lt;= arrayLen) &#123; int bigChild = leftChild; int rootElePrint = heapArray[leftChild-1]; int rightElePrint = heapArray[leftChild+1 -1] ; if(leftChild +1 &lt;= arrayLen &amp;&amp; heapArray[leftChild+1 -1] &gt; heapArray[leftChild-1]) &#123; bigChild = leftChild +1; &#125; if(heapArray[bigChild -1] &lt;= rootEle ) &#123; break; &#125; heapArray[curNode -1] = heapArray[bigChild -1]; curNode = bigChild; leftChild = curNode *2; &#125; heapArray[curNode -1] = rootEle; &#125; &#125; 源代码下载地址： http://download.csdn.net/detail/secondtonone1/9575112","categories":[{"name":"技术开发","slug":"tech","permalink":"http://www.limerence2017.com/categories/tech/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://www.limerence2017.com/tags/C/"},{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://www.limerence2017.com/tags/数据结构和算法/"}]},{"title":"C++模板类注意事项","date":"2017-08-04T04:16:19.000Z","path":"2017/08/04/cpptemp/","text":"最近使用C++模板，虽然工作几年了，但是模板用的很少，确切的说自己实现的机会很小。 昨天写了一个代码maxheap.h 中实现了类模板的声明，我将实现写在maxheap.cpp中， 当在main.cpp中引用maxheap中的接口时，提示链接错误。网上提供了几个解决方案， 第一种方式是将maxheap.h和maxheap.cpp包含在某个.h文件中，这样在main函数中 包含这个.h即可。第二种方式叫分离模式，我没看，觉得没必要搞得那么复杂。第三种方式 是我最看好的方式，就是将模板类的实现也放在.h中。C++ stl模板就是在.h中实现的。 C++编译文件将.cpp编译为.o文件，在链接阶段将.o文件链接生成可执行文件。问题 就出现在模板实现的.cpp文件并不在编译时实例化，读者可以试着在模板实现的.cpp里 写一些错误的代码，编译器并没有监测到，`因为模板实现的cpp没有参与编译。他需要在特定类型 绑定后才会实例化，是延时的`。 编译器使用模板，通过更换模板参数来创建数据类型。这个过程就是模板实例化(Instantiation)。 从模板类创建得到的类型称之为特例(specialization)。 模板实例化取决于编译器能够找到可用代码来创建特例(称之为实例化要素， point of instantiation)。 要创建特例，编译器不但要看到模板的声明，还要看到模板的定义。 模板实例化过程是迟钝的，即只能用函数的定义来实现实例化。 `所以将类模板的实现文件放在.h里，main函数包含该.h文件，当main函数用到该模板的特例化时 通过该.h就可以找到所有模板的实例化了`。链接也没问题。","categories":[{"name":"技术开发","slug":"tech","permalink":"http://www.limerence2017.com/categories/tech/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://www.limerence2017.com/tags/C/"}]},{"title":"C++ 局部静态变量，全局变量，全局静态变量，局部变量的区别和联系","date":"2017-08-04T04:07:00.000Z","path":"2017/08/04/cppvariable/","text":"C++变量根据定义位置的不同，具有不同的作用域，作用域可分为6种：全局作用域，局部作用域，语句作用域，类作用域，命名作用域和文件作用域。 从作用域看： 全局变量具有全局作用域。全局变量只需在一个源文件中定义，就可以作用于所有的源文件。当然，其他不包括全局变量定义的源文件需要用extern关键字再次声明这个全局变量。 静态局部变量具有局部作用域。它只被初始化一次，自从第一次初始化直到程序结束都一直存在，即它的生命周期是程序运行就存在，程序结束就结束， 他和全局变量的区别在于全局变量对所有的函数都是可见的，而静态局部变量只对定义自己的函数体始终可见。也就是在别的函数访问这个变量是错误的。 局部变量也只有局部作用域，他是自动对象，他在程序运行期间不是一直存在，而是只在函数执行期间存在，函数的一次调用结束后，变量就被撤销，其所占用的内存也被收回。 生命周期在函数结束后就结束了，作用域也仅限于该函数。 静态全局变量也具有全局作用域，他与全局变量的区别在于如果程序包含多个文件的话，他作用于定义它的文件里，不能作用到其他文件里，即被static关键字修饰过的变量具有文件作用域。 这样即使两个不同的源文件都定义了相同的静态全局变量，他们也是不同的变量。从分配内存空间看： 全局变量、静态局部变量、静态全局变量都在静态存储区分配空间，而局部变量在栈分配空间。 全局变量本身就是静态存储方式，静态全局变量当然也是静态存储方式。这两者在存储方式上没有什么不同。区别在于非静态全局变量的作用域是整个源程序，当一个源程序由多个源文件组成时，非静态的全局变量在各个源文件中都是有效的。而静态全局变量则限制了其作用域，即只在定义该变量的源文件内有效，在同一源程序的其他源文件中不能使用它。由于静态全局变量的作用域局限于一个源文件内，只能为该源文件内的函数公用，因此可以避免在其他源文件中引起错误。 1、静态变量会被放在程序的静态数据存储区里，这样可以在下一次调用的时候还可以保持原来的赋值。这一点是他与堆栈变量和堆变量的区别，单例模式就是利用这个机制。 2、变量用static告知编译器，自己仅仅在变量的作用域范围内可见。这一点是他与全局变量的区别。 从以上分析可以看出，把局部变量改变为静态变量后是改变了他的存储方式，即改变了他的生存期。把全局变量改变为静态变量后是改变了他的作用域，限制了他的使用范围， 因此static这个说明符在不同的地方起的作用是不同的。 TIPS： 1、若全局变量仅在单个文件中访问，则可以将这个变量修改为静态全局变量。 2、若全局变量仅在单个函数中使用，则可以将这个变量修改为该函数的静态局部变量。 3、全局变量、静态局部变量、静态全局变量都存放在静态数据存储区。 4、函数中必须要使用static变量的情况：当某函数的返回值为指针类型时，则必须是static的局部变量的地址作为返回值， 因为他的生命周期是整个程序运行周期。","categories":[{"name":"技术开发","slug":"tech","permalink":"http://www.limerence2017.com/categories/tech/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://www.limerence2017.com/tags/C/"}]},{"title":"TCP粘包处理","date":"2017-08-04T03:51:30.000Z","path":"2017/08/04/cpptcpnian/","text":"TCP（transport control protocol，传输控制协议）是面向连接的，面向流的，提供高可靠性服务。收发两端（客户端和服务器端）都要有一一成对的socket， 因此，发送端为了将多个发往接收端的包，更有效的发到对方，使用了优化方法（Nagle算法），将多次间隔较小且数据量小的数据，合并成一个大的数据块， 然后进行封包。这样，接收端，就难于分辨出来了，必须提供科学的拆包机制。即面向流的通信是无消息保护边界的。 UDP（user datagram protocol，用户数据报协议）是无连接的，面向消息的，提供高效率服务。不会使用块的合并优化算法， 由于UDP支持的是一对多的模式，所以接收端的skbuff(套接字缓冲区）采用了链式结构来记录每一个到达的UDP包， 在每个UDP包中就有了消息头（消息来源地址，端口等信息），这样，对于接收端来说，就容易进行区分处理了。 即面向消息的通信是有消息保护边界的。 TCP粘包我总结了几种情况tcp发送端发送三个包过来，tcp接收缓存区收到了这三个包，而用户的读写缓存区比这三个包的总大小还大， 此时数据是接受完全的，用户缓存区读到三个包需要分开，这是比较好处理的。第二种情况是因为用户的接收缓存区比tcp接受缓存区大，或者比tcp目前接收到的总数据大，那么用户缓存区读到 的数据就是tcp接收缓存区的数据，这是第一种情况的特例，这种情况需要判断那些包接受完全，那些包没接受完全。第三种情况是用户的接受缓存区比tcp接受缓存区要小，导致用户缓存区读到的数据是tcp接收缓存区 的一部分，这其中有完整的包，也有残缺的包。第四种情况是第三种情况的一个特例，用户缓存区的数据是不完全的，只是tcp缓存区的一部分。 对应特别大的那种包。 我提倡的解决办法就是首先实现一套从tcp缓存区中读取数据的数据结构和算法，因为tcp是面向 字节流的，将tcp缓存区中的数据读到用户缓存区里，这里我简单叫做outstreambuffer和instreambuffer， 这两个结构一个用于向tcp写，一个用于从tcp读。把tcp缓存区的数据尽可能多的读出来，不要判断是否是 完整的包，保证tcp缓存区没数据，这样会减少tcp粘包几率。 第二部就是将读到的数据，也就是instreambuffer中的数据进行分割，我叫做切包，切出一个个完整的包， 剩余不完整的留着下次继续接收。 第三步服务器应用层接口从instreambuffer中读取切割好的完整的包进行逻辑处理。 所以为了处理粘包和切包，需要我们自己设计包头，我设计的包头是八字节的结构体， 包含四字节的包id和四字节的包长度，这个长度既可以表示包头+消息体的长度， 也可以表示后面消息体的长度。我设计的是表示后面消息体的长度。 而上面所说的instreambuffer和outstreambuffer用户可以自己设计实现，也可以 利用成熟的网络库，我用的是libevent中的bufferevent，bufferevent实现了类似 的instreambuffer和outstreambuffer。 我设计的服务器部分代码如下，感兴趣可以去git下载： https://github.com/secondtonone1/smartserver 简单列举下接收端处理读数据的过程。1234void NetWorkSystem::tcpread_cb(struct bufferevent *bev, void *ctx)&#123; getSingleton().dealReadEvent(bev, ctx);&#125; networksystem是单例模式，处理读事件。因为静态函数tcpread_cb是libevent 设计格式的回调处理函数，在静态函数中调用非静态函数，我采用了单例调用。 1234567891011void NetWorkSystem::dealReadEvent(struct bufferevent *bev, void *ctx)&#123; // evutil_socket_t bufferfd = bufferevent_getfd(bev); std::map&lt;evutil_socket_t, TcpHandler *&gt;::iterator tcpHandlerIter = m_mapTcpHandlers.find(bufferfd); if(tcpHandlerIter != m_mapTcpHandlers.end()) &#123; tcpHandlerIter-&gt;second-&gt;dealReadEvent(); &#125;&#125; tcphandler是我设计的切包类，这里通过bufferfd找到对应的instream和outstream，从而处理里面的数据完成切包。123456789101112131415161718192021222324252627282930313233343536373839404142//处理读事件void TcpHandler::dealReadEvent()&#123; evbuffer * inputBuf = bufferevent_get_input(m_pBufferevent); size_t inputLen = evbuffer_get_length(inputBuf); while(inputLen &gt; 0) &#123; //tcphandler第一次接收消息或者该node接收完消息，需要开辟新的node接受消息 if(!m_pLastNode || m_pLastNode-&gt;m_nMsgLen &lt;= m_pLastNode-&gt;m_nOffSet) &#123; //判断消息长度是否满足包头大小，不满足跳出 if(inputLen &lt; PACKETHEADLEN) &#123; break; &#125; char data[PACKETHEADLEN] = &#123;0&#125;; bufferevent_read(m_pBufferevent, data, PACKETHEADLEN); struct PacketHead packetHead; memcpy(&amp;packetHead, data, PACKETHEADLEN); cout &lt;&lt; \"packetId is : \" &lt;&lt;packetHead.packetID &lt;&lt; endl; cout &lt;&lt; \"packetLen is : \" &lt;&lt; packetHead.packetLen &lt;&lt; endl; insertNode(packetHead.packetID, packetHead.packetLen); inputLen -= PACKETHEADLEN; &#125; //考虑可能去包头后剩余的为0 if(inputLen &lt;= 0) &#123; break; &#125; //读取去除包头后剩余消息 tcpRead(inputLen); &#125;&#125; 这个函数判断是否读完一个消息，读完就开辟新的节点存储新来的消息，否则就将新来的消息放入没读完的节点里。12345678910111213141516171819void TcpHandler::tcpRead(UInt32 &amp;inputLen)&#123; //node节点中的数据还有多少没读完 UInt32 remainLen = m_pLastNode-&gt;m_nMsgLen - m_pLastNode-&gt;m_nOffSet; UInt32 readLen = bufferevent_read(m_pBufferevent, m_pLastNode-&gt;m_pMsg + m_pLastNode-&gt;m_nOffSet, remainLen); //统计bufferevent 的inputbuffer中剩余的长度 inputLen -= readLen; //更改偏移标记 m_pLastNode-&gt;m_nOffSet += readLen; //判断读完 if(m_pLastNode-&gt;m_nOffSet &gt;= m_pLastNode-&gt;m_nMsgLen) &#123; m_pLastNode-&gt;m_pMsg[m_pLastNode-&gt;m_nMsgLen + 1] = '\\0'; cout &lt;&lt; \"receive msg is : \" &lt;&lt; m_pLastNode-&gt;m_pMsg &lt;&lt; endl; //cout &lt;&lt;\"read times is : \" &lt;&lt; ++readtimes&lt;&lt; endl; &#125;&#125; 我的服务器还在完善中，目前已经能处理连续收到1万个包的切包和大并发的问题了，最近在设计应用层的序列化 和应用层消息回调。感兴趣可以下载看看，下载地址：https://github.com/secondtonone1/smartserver","categories":[{"name":"技术开发","slug":"tech","permalink":"http://www.limerence2017.com/categories/tech/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://www.limerence2017.com/tags/C/"},{"name":"网络编程","slug":"网络编程","permalink":"http://www.limerence2017.com/tags/网络编程/"}]},{"title":"C++单例模式设计和实现","date":"2017-08-04T03:44:16.000Z","path":"2017/08/04/cppsingle/","text":"C++单例模式主要用途就是整个程序中只实例化一个对象，之后获取到的都是该对象本身进行处理问题。 单例模式一般都是在函数中采用局部静态变量完成的，因为局部的静态变量生命周期是随着程序的生命周期 一起结束，所以不用担心会失效。另外局部的静态变量作用域仅限于该函数内部，别的函数不会直接使用。 第三点就是局部的静态变量跟所有的静态变量一样，放在全局区(静态区)，只被初始化一次。下面是我结合模板设计的单例类 1234567891011121314151617181920212223242526272829#ifndef _SINGLETON_CLASS_H_#define _SINGLETON_CLASS_H_template &lt;class Type&gt;class Singleton&#123;protected : Singleton()&#123;&#125;public: static Type &amp; getSingleton() &#123; return singleton; &#125;private: Singleton(const Singleton &amp; temp)&#123; singleton = temp.singleton; &#125;private: static Type singleton;&#125;;template &lt;class Type&gt;Type Singleton&lt;Type&gt;::singleton;#endif 其余的类继承就可以了。 需要注意类的静态成员变量，如果不是integer type，需要在类外完成初始化。 int属于integer type，在类内可以完成初始化。 其余的类继承该类： 1234567891011121314class NetWorkSystem : public Singleton&lt;NetWorkSystem&gt;&#123;public: NetWorkSystem():m_nListenfd(0),m_pEvent_base(NULL),m_nConnId(0)&#123;&#125; bool initial(); static void tcpread_cb(struct bufferevent *bev, void *ctx); static void tcpwrite_cb(struct bufferevent *bev, void *ctx); static void tcperror_cb(struct bufferevent *bev, short what, void *ctx); static void listener_read_cb(evutil_socket_t fd, short what, void *p); void run(); void release(); //... &#125;; 使用时使用getsinggleton这个函数即可。 这是我服务器中截取的代码，可以从github中下载该服务器源码。 下载地址：https://github.com/secondtonone1/smartserver 服务器自己做的，还在不断地完善之中。","categories":[{"name":"技术开发","slug":"tech","permalink":"http://www.limerence2017.com/categories/tech/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://www.limerence2017.com/tags/C/"}]},{"title":"Hello World","date":"2017-08-04T03:15:43.158Z","path":"2017/08/04/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"Google protocol buffer的配置和使用(Linux&&Windows)","date":"2017-08-04T03:15:30.000Z","path":"2017/08/04/probuff/","text":"最近自己的服务器做到序列化这一步了，在网上看了下，序列化的工具有boost和google的protocol buffer，protocol buffer的效率和使用程度更高效一些，就自己琢磨下把他加到自己的服务器里。所以这里我先弄一个小的demo去测试如何使用和配置protocol buffer。首先是windows 平台 windows下protocol buffer 配置： 下载protocol buffer， 去google官网或者其他渠道下载protocol buffer包 解压zip文件，进入vs文件夹编译protocol buffer，图示如下 工程下的几个项目都编译一遍，会生成几个lib在vs目录下的debug目录里能看到protoc.exe 和 libprotobuf.lib, libprotobuf-lite.lib , libprotoc.lib这几个lib是新生成的，先放一放，以后会用到。到此为止，google protocol buffer的配置和库已经生成，我们下一步设计自己的proto文件，并生成对应的pb.h和pb.cc 编写自己的proto 格式如下 123456789package smart;message test&#123; required string name = 1; required int32 age = 2; optional string email = 3; &#125; package 表示声明为包名，package smart;表示包名为smart, message test定义一个消息体，花括号结束不需要分号,括号内是成员变量，成员变量后面的数字默认从1开始，依次递增。 required表示这个字段必须有，optional表示字段可选，还有一些repeated表示可重复的值域，常用于数组。总结下：数据结构体： message message_name{message_body;} message_body格式： 例如 required int32 query = 1[defaut=10]; 形式为：rule type name = value[other_rule]; 规则： required表示必须具有该值域； optional表示可选的值域； repeated表示可重复的值域(即&gt;=0)； 其中requered/optional是常用rule，而repeated则不常用同时因为是历史遗留现使用repeated int32 samples=4[packed=true];形式； value值： value值最小为1，是底层编码时使用其中1-15占一位，&gt;15则会占多位； 不同的message中的value值互不干扰,常以1开始计数。 保存为包名.消息名.proto的形式，我保存为smart.msg.proto 接下来进行编译这个smart.msg.proto， protobuf提供了protoc命令 protoc –proto_path=(.proto文件路径) –cpp_out=(.cc .java生成文件路径) (.proto文件路径)/?.proto –proto_path 简化为: -I 其中可根据需要更改:cpp_out选项为java_out/python_out。 举例： protoc -I=./ –cpp_out=./ ./smart.msg.proto windows环境下打开cmd，进入到protocol buf vs目录里debug文件夹里调用protoc命令 我的proto放在D:\\win32projects\\protobuftest\\ProtoBuf目录，所以如下：进入D:\\win32projects\\protobuftest\\ProtoBuf下可看到新生成的文件到目前为止，准备工作都做完了，下一步建立自己的项目，使用这些.h和.cc 建立vs项目，我命名为protobuftest，在项目目录里建立Include和Lib，Protobuf 文件夹，将protobuff库的src文件夹拷贝到Include里，将libprotobuf.lib, libprotobuf-lite.lib , libprotoc.lib拷贝到Lib文件里，将smart.msg.proto拷贝到Protobuf中， 将protobuff库的那个debug也拷贝到Protobuf中，因为我想通过写一个批处理文件在该项目 里生成.h和.cc文件。 Lib文件夹: Include文件夹： Protobuf文件夹：bat如下：123cd .\\Debugprotoc -I=..\\ --cpp_out=..\\ ..\\smart.msg.protopause 将ProtoBuf文件夹里的.h和.cc添加到项目里 配置项目属性C/C++ —-&gt; General —&gt; Additional Include Directories ..\\Include\\src Linker—&gt;General —-&gt; Additional Library Directories ..\\Lib 顺便把预编译也关了 项目配置好后写代码：1234567891011121314151617181920212223242526272829303132#include \"stdafx.h\"#include &lt;iostream&gt;#include &lt;fstream&gt;#include \"../ProtoBuf/smart.msg.pb.h\"#pragma comment(lib, \"libprotobuf.lib\") #pragma comment(lib, \"libprotoc.lib\")int _tmain(int argc, _TCHAR* argv[])&#123; smart::test msg1; msg1.set_age(101); msg1.set_name(\"nice to meet you!\"); std::fstream out(\"User.pb\", std::ios::out | std::ios::binary | std::ios::trunc); msg1.SerializeToOstream(&amp;out); out.close(); smart::test msg2; std::fstream in(\"User.pb\", std::ios::in | std::ios::binary); if (!msg2.ParseFromIstream(&amp;in)) &#123; std::cerr &lt;&lt; \"Failed to parse User.pb.\" &lt;&lt; std::endl; exit(1); &#125; std::cout &lt;&lt; msg2.age() &lt;&lt; std::endl; std::cout &lt;&lt; msg2.name() &lt;&lt; std::endl; std::cout &lt;&lt; msg2.email() &lt;&lt; std::endl; std::cout &lt;&lt; \"adfdf\" &lt;&lt;std::endl; getchar(); return 0;&#125; 测试输出到此为止windows环境配置和使用google protocol buffer已经解决。 Linux环境配置和使用： 解压编译配置，敲命令就可以了： 123456unzip protobuf-2.6.1 cd protobuf-2.6.1 ./configure --prefix=/usr/local/protobuf-2.6.1 make make check make install 写proto文件和编译，跟上面的相同： 连带.cc文件一同编译，生成目标并执行，以后会写成makefile，这只是个测试程序，就简单测试下记得编译时带上-lpthread 和-lprotobuf如果运行时提示找不到libprotobuf9.so这个库，可以敲这个命令export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib到此为止就完成了google protobuf的 学习和配置","categories":[{"name":"技术开发","slug":"tech","permalink":"http://www.limerence2017.com/categories/tech/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://www.limerence2017.com/tags/C/"},{"name":"网络编程","slug":"网络编程","permalink":"http://www.limerence2017.com/tags/网络编程/"}]},{"title":"C++的一些注意事项","date":"2017-08-04T02:37:25.000Z","path":"2017/08/04/cppimportant/","text":"一. C++类的引用成员，类的常量成员，类的static成员的初始化方式类的引用成员和常量成员初始化放在初始化列表里，因为初始化只有一次，需要在构造函数之前进行初始化，写在类的构造函数会出错。类的static变量要放在类声明的外边定义，因为static变量属于整个类，而不是类对象，所以不能放在类的构造函数里。举个例子：一个类中既有常量成员也有引用成员12345678910111213141516class MyClass&#123;public: MyClass(int value):a(1),b(a), m_nValue(value),c(m_nValue),d(m_nValue)&#123;&#125;public: const int a; const int &amp; b; int &amp; c; const int &amp;d; int m_nValue; static tms s; static double f;&#125;;tms MyClass::s;double MyClass::f = 0.33; 类的引用成员必须在类的初始化列表初始化，而且必须初始化，否则编译出错。类的static成员需要在类外定义，否则使用时会出错。类的常引用和引用的区别是 可以通过引用修改引用对象的数值，不可以通过常引用修改引用对象的数值 引用可以更改引用的对象，从而引用另一个变量，常引用是不能更改引用的对象的。 常引用可以引用非常量(变量)和常量以及右值，引用只能引用变量。 当常引用引用变量的时候，可以修改变量值，常引用的数值会随着改变，但是不能直接修改常引用。 下面是测试 二 类的常对象调用的接口必须都为常函数，很多人写法不注意编译会报错。代码示例为自己的一个项目，msgStream为常引用，那么他内部的列表返回的迭代器需要用const_iterator12345678910111213MsgStream( const MsgStream &amp; msgStream)&#123; m_nCount = msgStream.m_nCount; msgStream.m_listConMsg.begin(); for(std::list&lt;ConMsgNode&gt;::const_iterator msgIter = msgStream.m_listConMsg.begin(); msgIter != msgStream.m_listConMsg.end(); msgIter++ ) &#123; m_listConMsg.push_back(*msgIter); &#125; &#125; msgStream 这个常引用也只能调用常量成员函数， 函数体后有const声明的函数 三析构函数的顺序，构造函数的顺序 当类子类中包含其他的类，构造的顺序是先构造基类对象，然后构造子类包含的类对象，最后构造子类对象。 当基类中包含其他的类，构造的顺序是先构造基类中包含的类对象，然后构造基类对象，最后构造子类对象。 当类子类中包含其他的类，析构的顺序是先构子类对象，然后析构子类包含的其他类对象，最后析构基类。 当基类中包含其他的类，析构的顺序是先析构子类对象，然后析构基类对象，最后析构基类中其他对象。 123456789101112131415161718192021222324252627282930class c&#123;public: c()&#123; printf(\"c\\n\"); &#125;protected:private:&#125;;class b &#123;public: b()&#123; printf(\"b\\n\");&#125;protected: c C;private:&#125;;class a : public b&#123;public: a()&#123; printf(\"a\\n\"); &#125;protected:private:&#125;;int main()&#123; a A; getchar();&#125; 结果： 123456789101112131415161718192021222324252627282930class c&#123;public: c()&#123; printf(\"c\\n\"); &#125;protected:private:&#125;;class b &#123;public: b()&#123; printf(\"b\\n\");&#125;protected:private:&#125;;class a : public b&#123;public: a()&#123; printf(\"a\\n\"); &#125;protected: c C;private:&#125;;int main()&#123; a A; getchar();&#125; 结果： 123456789101112131415161718192021222324252627282930313233class c&#123;public: c()&#123;&#125; ~c()&#123; printf(\"c\\n\"); &#125;protected:private:&#125;;class b &#123;public: b()&#123;&#125; ~b()&#123; printf(\"b\\n\");&#125;protected:private:&#125;;class a : public b&#123;public: a()&#123;&#125; ~a()&#123; printf(\"a\\n\"); &#125;protected: c C;private:&#125;;int main()&#123; a A; return 0;&#125; 结果： 四 list 直接赋值给另外一个list，并不会导致list元素的深拷贝，两个list中的元素是同一份数据","categories":[{"name":"技术开发","slug":"tech","permalink":"http://www.limerence2017.com/categories/tech/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://www.limerence2017.com/tags/C/"}]},{"title":"windows多线程接口介绍和使用","date":"2017-08-03T12:47:18.000Z","path":"2017/08/03/winmulthread/","text":"一windows多线程接口：1 创建线程CreateThread 与 _beginthreadex都可以实现创建线程，两个函数的参数相同， 12345678 HANDLEWINAPICreateThread( LPSECURITY_ATTRIBUTESlpThreadAttributes, SIZE_TdwStackSize, LPTHREAD_START_ROUTINElpStartAddress, LPVOIDlpParameter, DWORDdwCreationFlags, LPDWORDlpThreadId); 函数说明： 第一个参数表示线程内核对象的安全属性，一般传入NULL表示使用默认设置。 第二个参数表示线程栈空间大小。传入0表示使用默认大小（1MB）。 第三个参数表示新线程所执行的线程函数地址，多个线程可以使用同一个函数地址。 第四个参数是传给线程函数的参数。 第五个参数指定额外的标志来控制线程的创建，为0表示线程创建之后立即就可以进行调度，如果为CREATE_SUSPENDED则表示线程创建后暂停运行，这样它就无法调度，直到调用ResumeThread()。 第六个参数将返回线程的ID号，传入NULL表示不需要返回该线程ID号。 函数返回值： 成功返回新线程的句柄，失败返回NULL。 CreateThread 与 _beginthreadex的区别是_beginthreadex更安全一些，_beginthreadex会为每个线程分配一些独立的数据块，这个独立的数据块用于保存线程独有的信息，因 为在调用C的标准库时，有些函数是返回的是全局信息，这个全局信息容易被多线程干扰，_beginthreadex会规避这个问题。 2线程等待函数WaitForSingleObject，WaitForSingleObject这个函数使线程等待某个特定的对象，使线程进入等待状态，直到指定的内核对象被触发。 DWORDWINAPIWaitForSingleObject( HANDLEhHandle, DWORDdwMilliseconds); 函数说明： 第一个参数为要等待的内核对象。 第二个参数为最长等待的时间，以毫秒为单位，如传入5000就表示5秒，传入0就立即返回，传入INFINITE表示无限等待。 因为线程的句柄在线程运行时是未触发的，线程结束运行，句柄处于触发状态。所以可以用WaitForSingleObject()来等待一个线程结束运行。函数返回值：在指定的时间内对象被触发，函数返回WAIT_OBJECT_0。超过最长等待时间对象仍未被触发返回WAIT_TIMEOUT。传入参数有错误将返回WAIT_FAILED 具体的使用 可以从我自己做的服务器里截取一部分代码看看 1234567891011121314151617181920212223242526272829303132333435363738394041424344void BaseThread::startup(UInt32 stackSize)&#123; assert(m_nId == 0); #if defined _WIN32 m_hThread =(HANDLE) _beginthreadex(NULL,0,threadFunc, this, 0, &amp;m_nId); //cout &lt;&lt; this &lt;&lt;endl; ::SetThreadPriority(::GetCurrentThread(), 2); //让线程跑起来后再退出函数 // Sleep(1000); #endif&#125;void BaseThread::join()&#123; #if defined _WIN32 DWORD exitCode; while(1) &#123; if(GetExitCodeThread(m_hThread, &amp;exitCode) != 0) &#123; if(exitCode != STILL_ACTIVE) &#123; break; &#125; else &#123; // wait之前， 需要唤起线程， 防止线程处于挂起状态导致死等 ResumeThread(m_hThread); WaitForSingleObject(m_hThread, INFINITE); &#125; &#125; else &#123; break; &#125; &#125; CloseHandle(m_hThread); #endif m_nId = 0;&#125;","categories":[{"name":"技术开发","slug":"tech","permalink":"http://www.limerence2017.com/categories/tech/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://www.limerence2017.com/tags/C/"},{"name":"Windows环境编程","slug":"Windows环境编程","permalink":"http://www.limerence2017.com/tags/Windows环境编程/"}]},{"title":"Windows互斥锁demo和分析","date":"2017-08-03T12:36:08.000Z","path":"2017/08/03/winmutexdemo/","text":"一：windows创建锁接口创建互斥锁的方法是调用函数CreateMutex12345HANDLE CreateMutex(LPSECURITY_ATTRIBUTESlpMutexAttributes, // 指向安全属性的指针BOOLbInitialOwner, // 初始化互斥对象的所有者LPCTSTRlpName // 指向互斥对象名的指针); 第一个参数是一个指向SECURITY_ATTRIBUTES结构体的指针，一般的情况下，可以是nullptr。 第二个参数类型为BOOL，表示互斥锁创建出来后是否被当前线程持有。 第三个参数类型为字符串（const TCHAR*），是这个互斥锁的名字，如果是nullptr，则互斥锁是匿名的。 例子： HANDLE hMutex = CreateMutex(nullptr, FALSE, nullptr); 二：windows持有锁接口：DWORD WaitForSingleObject( HANDLE hHandle,DWORD dwMilliseconds); 这个函数的作用比较多。这里只介绍第一个参数为互斥锁句柄时的作用。 它的作用是等待，直到一定时间之后，或者，其他线程均不持有hMutex。第二个参数是等待的时间（单位：毫秒），如果该参数为INFINITE，则该函数会一直等待下去。 三：释放锁BOOL WINAPI ReleaseMutex(HANDLE hMutex); 四：销毁BOOL CloseHandle(HANDLE hObject); 下面是网上的一个案例，根据我自己做服务器的需求，模仿者写了一个： ‘’’ cpp//各种类型的锁的基类class BaseLock{public: BaseLock(){} virtual ~BaseLock(){} virtual void lock() const = 0 ; virtual void unlock() const = 0 ;}; //互斥锁继承基类class Mutex :public BaseLock{public: Mutex(); ~Mutex(); virtual void lock() const; virtual void unlock() const;private: #if defined _WIN32 HANDLE m_hMutex; #endif}; //互斥锁实现文件： //在构造函数里创建锁Mutex::Mutex(){ #if defined _WIN32 m_hMutex = ::CreateMutex(NULL, FALSE, NULL); #endif } //析构函数里销毁锁Mutex::~ Mutex(){ #if defined _WIN32 ::CloseHandle(m_hMutex); #endif } //互斥锁上锁void Mutex::lock() const{ #if defined _WIN32 DWORD d = WaitForSingleObject(m_hMutex, INFINITE); #endif } //互斥锁解锁void Mutex::unlock() const{ #if defined _WIN32 ::ReleaseMutex(m_hMutex); #endif } class CLock{public: CLock(const BaseLock &amp; baseLock):m_cBaseLock(baseLock){ //构造函数里通过基类锁调用加锁函数(多态) m_cBaseLock.lock(); } ~CLock(){ //析构函数先解锁 m_cBaseLock.unlock(); }private: //常引用变量，需要在初始化列表初始 //多态机制 const BaseLock&amp; m_cBaseLock;};‘’’ CLock是留给外界使用的接口类，可以实现自动加锁和解锁。构造函数传入不同类型的锁，目前只实现了互斥锁，通过基类类型的引用成员可以实现多态调用不同的lock和unlock，而CLock析构函数因为会调用基类的unlock，从而实现不同类型的解锁。那么读者可能会有疑问互斥锁什么时候会销毁？互斥锁的销毁写在互斥锁类的析构函数里，当调用互斥锁的析构函数就会自动销毁这把锁了。什么时候调用互斥锁的析构函数呢？之前有介绍过，析构函数的调用顺序，先析构子类对象，然后析构子类对象中包含的其他类型的对象，最后析构基类对象，所以整个流程是先调用Mutex的构造函数，将Mutex构造的对象传入CLock的构造函数，这样实现自动加锁，当CLock析构的时候先析构CLock对象，之后析构CLock类里的BaseLock对象，因为是多态，会自动根据虚析构函数调用子类也就是MutexLock的析构函数，完成销毁锁的操作。 下面是我服务器中的一段代码截取，算是这个锁的示例 123456789void NetWorker::pushNodeInStream(TcpHandler * tcpHandler)&#123; //加锁处理消息加入到instream里 Mutex mutexlock; CLock mylock(mutexlock); list&lt;MsgNode *&gt; * msgList = tcpHandler-&gt;getListMsgs();&#125; 因为函数}会释放局部变量，那么就会调用CLock析构函数，接着调用Mutex析构函数。依次完成解锁和销毁锁的操作。我的服务器还在制作当中，基本框架制作完毕会做一些服务器设计的研究。","categories":[{"name":"技术开发","slug":"tech","permalink":"http://www.limerence2017.com/categories/tech/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://www.limerence2017.com/tags/C/"},{"name":"Windows环境编程","slug":"Windows环境编程","permalink":"http://www.limerence2017.com/tags/Windows环境编程/"}]},{"title":"windows环境利用semophore机制进行线程同步","date":"2017-08-03T10:23:28.000Z","path":"2017/08/03/winsemphore/","text":"semophore是信号量的意思，常用于PV操作，所谓PV操作就是pend(等待，直到有资源可用，并且消耗资源)V就是释放资源。semophore和mutex区别，mutex本意为互斥，用于线程独占资源，常用于临界区访问锁住mutex，当线程A对mutex加锁后，其他线程不能反问临界资源，也不能加锁，直到线程A解锁，其他线程才能访问。而semophore则可以在不同的线程之间进行pv操作，semophore可以设置最多有多少个信号量，以及初始的信号量，当调用V操作的时候信号量数量增加一个，调用P操作时候信号量数量减少一个，但是不能超过最多的信号量。信号量是一个非负数。打个比方，一辆车只有一把钥匙，mutex就是这把钥匙，谁有这把钥匙才能开车，开完车把钥匙归还或者给下一个等待的人。现在有一辆公交车，最多容纳二十个人，二十就是信号量的最大值，每个人就是一个信号量，当人满的时候其他的人就不能上车，直到有人下车，其他人才能上车。 semophore主要适用于windows环境下的同步 下面介绍下semophore1 创建信号量1234567891011HANDLE WINAPI CreateSemaphore( _In_opt_ LPSECURITY_ATTRIBUTES lpSemaphoreAttributes _In_ LONG lInitialCount, _In_ LONG lMaximumCount, _In_opt_ LPCTSTR lpName ); 第一个参数：安全属性，如果为NULL则是默认安全属性 第二个参数：信号量的初始值，要&gt;=0且&lt;=第三个参数 第三个参数：信号量的最大值 第四个参数：信号量的名称 返回值：指向信号量的句柄，如果创建的信号量和已有的信号量重名，那么返回已经存在的信号量句柄 2打开其他进程中的信号量12345HANDLE WINAPI OpenSemaphore( _In_ DWORD dwDesiredAccess, _In_ BOOL bInheritHandle, _In_ LPCTSTR lpName ); dwDesiredAccess：指定想要的访问权限，SEMAPHORE_ALL_ACCESS 请求对事件对象的完全访问，SEMAPHORE_MODIFY_STATE 修改状态权限，使用ReleaseSemaphore函数需要该权限；bInheritHandle：是否希望子进程继承信号量对象的句柄，一般设置为false；lpName：要打开的信号量对象的名称； 3等待信号量1234DWORD WINAPI WaitForSingleObject( _In_ HANDLE hHandle, _In_ DWORD dwMilliseconds ); hHandle：指向内核对象的句柄；dwMilliseconds：线程最大等待多长时间，直到该对象被触发。经常使用INFINITE，表示阻塞等待。WaitForSingleObject为等待资源的函数，等待内核对象被触发的通用函数，在这里用于等待信号量，我们之前说过信号量的资源数是非负整数，当信号量数量大于0，那么该函数会将信号量-1，并且返回，线程继续执行后续操作。如果信号量资源数为0，那么该线程处于等待状态，阻塞等待信号量被激活。 4 释放信号量12345BOOL WINAPI ReleaseSemaphore( _In_ HANDLE hSemaphore, _In_ LONG lReleaseCount, _Out_opt_ LPLONG lpPreviousCount ); hSemaphore：信号量内核对象的句柄；lReleaseCount：释放自己使用的资源数目，加到信号量的当前资源计数上，通常会传1，当然是根据线程使用的资源数目而定。lpPreviousCount：返回当前资源计数的原始值，应用程序很少会用到这个值，所以一般置为NULL；当一个线程使用完信号量对象控制的有限资源后，应该调用ReleaseSemaphore，释放使用的资源，使信号量对象的当前资源计数得到恢复。 5关闭内核对象的句柄123BOOL WINAPI CloseHandle( _In_ HANDLE hObject ); hObject：指向内核对象的句柄和其他内核对象一样，无论以什么方式创建内核对象，我们都必须通过调用CloseHandle向系统表明结束使用内核对象。如果传入的句柄有效，系统将获得内核对象数据结构的地址，并将结构中的使用计数减1，如果使用计数0，就会将内核对象销毁，从内存空间中擦除。下面写一个例子，三个线程，分别为如数1,2,3，要求每个线程输出10此，以1,2,3分别输出。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081//先定义三个信号量句柄：HANDLE hsem1,hsem2,hsem3; //线程回调函数：unsigned __stdcall threadFunA(void *)&#123; for(int i = 0; i &lt; 10; i++)&#123; WaitForSingleObject(hsem1, INFINITE);//等待信号量 cout&lt;&lt;\"first thread function\"&lt;&lt;endl; ReleaseSemaphore(hsem2, 1, NULL);//释放信号量2 &#125; return 1;&#125;//该函数内部调用等待第一个信号量，如果获得资源，则打印日志，并且释放资源2//同样的道理，完成第二个，第三个线程回调函数unsigned __stdcall threadFunB(void *)&#123; for(int i = 0; i &lt; 10; i++)&#123; WaitForSingleObject(hsem2, INFINITE);//等待信号量 cout&lt;&lt;\"second thread function\"&lt;&lt;endl; ReleaseSemaphore(hsem3, 1, NULL);//释放信号量3 &#125; return 2;&#125; unsigned __stdcall threadFunC(void *) &#123; for(int i = 0; i &lt; 10; i++)&#123; WaitForSingleObject(hsem3, INFINITE);//等待信号量 cout&lt;&lt;\"third thread function\"&lt;&lt;endl; ReleaseSemaphore(hsem1, 1, NULL);//释放信号量 &#125; return 3; &#125;//接下来在主函数创建三个线程，并且初始化第一个信号量的初始资源数为1，//第二个和第三个信号量初始资源数都是0，他们的最大资源数为1.//创建信号量 hsem1 = CreateSemaphore(NULL, 1, 1, NULL); hsem2 = CreateSemaphore(NULL, 0, 1, NULL); hsem3 = CreateSemaphore(NULL, 0, 1, NULL); HANDLE hth1, hth2, hth3; //创建线程 hth1 = (HANDLE)_beginthreadex(NULL, 0, threadFunA, NULL, 0, NULL); hth2 = (HANDLE)_beginthreadex(NULL, 0, threadFunB, NULL, 0, NULL); hth3 = (HANDLE)_beginthreadex(NULL, 0, threadFunC, NULL, 0, NULL); //当线程调用完回调函数才能让主线程退出，linux系统对应的api为pthread_join()，//我们这里windows api为 WaitForSingleObject//等待子线程结束 WaitForSingleObject(hth1, INFINITE); WaitForSingleObject(hth2, INFINITE); WaitForSingleObject(hth3, INFINITE); //最后释放线程的句柄和信号量的句柄 //一定要记得关闭线程句柄 CloseHandle(hth1); CloseHandle(hth2); CloseHandle(hth3); CloseHandle(hsem1); CloseHandle(hsem2); CloseHandle(hsem3); 打印输出如下：结果显示三个线程是按顺序输出的。所以信号量常用来同步线程。源代码下载地址：semophore测试","categories":[{"name":"技术开发","slug":"tech","permalink":"http://www.limerence2017.com/categories/tech/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://www.limerence2017.com/tags/C/"},{"name":"Windows环境编程","slug":"Windows环境编程","permalink":"http://www.limerence2017.com/tags/Windows环境编程/"}]},{"title":"windows环境下封装条件wait和signal","date":"2017-08-03T09:46:34.000Z","path":"2017/08/03/winsignal/","text":"linux 环境有提供好的pthread_cond_wait() 和 phread_signal()、pthread_broadcast()windows需要自己封装，利用semophore控制线程等待和释放，先简单谈一下设计好后api该如何使用。假设我们封装好条件变量等待函数名字叫做wait(Mutex&amp; mutex)，Mutex是之前我们封装的条件变量，文章最下边会给出这些文件的下载地址，在这里读者当做linux 的mutex即可。我们封装的释放函数为signal(),广播函数为broadcast。判断等待条件变量和逻辑处理如下：12345678910111213Lock(mutex);while(条件不满足)&#123; wait(mutex);&#125;todo...;UnLock(mutex); 激活条件变量如下：123456789101112131415Lock(mutex); todo ...; if(条件满足) &#123; signal();/broadcast(); &#125; signal();UnLock(mutex); Condition 是我们封装的条件变量类这是封装好api后调用规则，那么先考虑wait内部的基本形式1234567891011121314151617181920212223void Condition::wait(Mutex &amp;mutex)&#123; //1 Condition 类中表示阻塞线程数 mblocked ++; //2 解锁，释放互斥量 UnLock(mutex); //3 阻塞等待 mQueue为信号量 res = WaitForSingleObject(reinterpret_cast&lt;HANDLE&gt;(mQueue), INFINITE); //4 做一些判断和逻辑处理 //5 加锁 Lock(mutex);&#125; wait内部记录一个阻塞的线程数mblocked，mblocked 是我们封装Condition类的成员变量，然后释放外部的互斥量，然后调用阻塞函数，等待signal唤醒。当WaitForSingleObject获取信号后会继续执行，做一些逻辑判断，最后将mutex锁住。这里用到的mQueue是一个信号量，用信号量可以接受多个唤醒和控制线程唤醒数量。下面是条件变量释放的函数，我们先做只是放一个条件变量的api123456789101112131415161718192021222324void Condition::signal()&#123; //1阻塞的线程减少 mblocked --; //2将激活的信号个数设置为1 signals = 1; //3 if (signals) &#123; //释放信号量 res = ReleaseSemaphore(reinterpret_cast&lt;HANDLE&gt;(mQueue), signals, 0); ASSERT(res); &#125;&#125; 先不要着急往下写，考虑下这么做真的合适么？首先之前设计过外部调用1234567if(条件满足) &#123; signal();/broadcast(); &#125; 这个只要条件满足就可以激活，所以我们只用mblocked表示阻塞线程数是不够的，当信号量被激活很多没有被消耗的情况下就需要统计当前可用的资源数，那么就在Condition类添加mWait表示当前可用的信号量个数。除此之外，考虑这样一种情况，当条件不满足的时候 线程A调用void wait(Mutex &amp;mutex)函数，wait函数先解锁再阻塞，对应wait中第2,3步骤。而另一个线程B当条件满足时调用 signal函数激活之前阻塞的线程A，对应signal函数中第3步。原阻塞线程A因为捕获到信号量，所以一次走到wait中第4、5步。由于第4和第5步之间没有加锁保护，所以这一阶段用到的类的成员变量都是不安全的。所以在第3和第4之间加一个互斥锁，第5步之后释放这个互斥锁。同样的道理，为了避免此时signal内部调用类的成员变量造成数据不一致所以signal内部也需要加锁，在signal内部第1步之前加锁，第3步之后解锁，或者第3步之前解锁都可以。我觉得在第三步之前释放会好一些，在释放信号量之前解锁，避免死锁。所以添加一个成员变量mMutex用于部分代码互斥。那么改良后我们的函数如下： 12345678910111213141516171819202122232425262728voidCondition::wait(Mutex&amp; mutex)&#123; #ifndef WIN32 int ret = pthread_cond_wait(&amp;mId, mutex.getId()); ASSERT(ret == 0); #else //1 mBlocked++;&lt;br&gt; //2 mutex.unlock(); int res = 0;&lt;br&gt; //3 res = WaitForSingleObject(reinterpret_cast&lt;HANDLE&gt;(mQueue), INFINITE); ASSERT(res == WAIT_OBJECT_0); //用于暂时存储mWaiting的数值 unsigned wasWaiting = 0; //4 res = WaitForSingleObject(reinterpret_cast&lt;HANDLE&gt;(mMutex), INFINITE); ASSERT(res == WAIT_OBJECT_0); wasWaiting = mWaiting; //5 res = ReleaseMutex(reinterpret_cast&lt;HANDLE&gt;(mMutex)); ASSERT(res); //6 mutex.lock();#endif&#125; 步骤也做了相应的调整。1234567891011121314151617181920212223242526272829303132333435363738394041424344voidCondition::signal ()&#123;#ifndef WIN32 int ret = pthread_cond_signal(&amp;mId); ASSERT(ret == 0);#else unsigned signals = 0; int res = 0; //1 res = WaitForSingleObject(reinterpret_cast&lt;HANDLE&gt;(mMutex), INFINITE); ASSERT(res == WAIT_OBJECT_0); //2 if (mWaiting != 0) &#123; if (mBlocked == 0) &#123; res = ReleaseMutex(reinterpret_cast&lt;HANDLE&gt;(mMutex)); ASSERT(res); return; &#125; ++mWaiting; --mBlocked; signals = 1; &#125; else &#123; signals = mWaiting = 1; --mBlocked; &#125; //3 res = ReleaseMutex(reinterpret_cast&lt;HANDLE&gt;(mMutex)); ASSERT(res); //4 if (signals) &#123; res = ReleaseSemaphore(reinterpret_cast&lt;HANDLE&gt;(mQueue), signals, 0); ASSERT(res); &#125;#endif&#125; 改良后更新了步骤，注释的就是步骤，方便接下来讨论这两段代码的隐患，因为仅仅这些还不够。目前现总结下mMutex作用： 1 mMutex用于signal函数内部和wait函数 获取信号量之后的代码互斥，保护类的常用变量。 2 当不同的线程调用wait等待后获得激活时，mMutex保证获得信号量之后的操作是互斥的，安全的。 由于调用wait函数之前需要加外部的互斥锁，所以不同的线程调用wai函数时第一步的mBlocked++是互斥的，不会出错。 唯一有可能出错的是那种情况呢？ 就是当signal发出信号后，当前有一个因为调用wait阻塞的线程A捕获到该信号，进入第四步，修改或者访问mBlocked变量的值，与此同时有线程A调用wait函数，此时会进入wait内部第一步mBlocked++，多线程修改和读取mBlocked会造成数据混乱，所以此时需要在第一步之前加锁，第2步之前解锁，因此添加单个信号量mGate，用于控制当有线程处于解锁状态处理mBlocked等类成员时，其他线程进入wait修改mBlocked值。这个res = WaitForSingleObject(reinterpret_cast(mGate), INFINITE);可以放在wait函数第4步之后，当第4步获得互斥资源后，阻塞等待获取mGate信号，如果没获得需要等待别的线程释放mGate，如果此时mGate不被释放造成mMutex死锁。所以别的线程中先调用 WaitForSingleObject(reinterpret_cast(mGate), INFINITE);后调用WaitForSingleObject mMutex会造成死锁。需要特别注意。如果规避了这一点，那么就可以避免死锁。所有情况都对mGate互斥访问并不友好，出现之前讨论的情况只有一种：就是当前应用程序中至少有一个线程处于等待，而signal释放信号后，某一个等待的线程继续执行4后面的操作，外界有新的线程调用wait时修改mBlocked会出错。所以只需要在signal函数中判断当mWaiting数量为0时对mGate加锁，mWait根据不同情况进行对mGate进行释放。修改后的代码如下： 12345678910voidCondition::enterWait ()&#123; int res = 0; res = WaitForSingleObject(reinterpret_cast&lt;HANDLE&gt;(mGate), INFINITE); ASSERT(res == WAIT_OBJECT_0); ++mBlocked; res = ReleaseSemaphore(reinterpret_cast&lt;HANDLE&gt;(mGate), 1, 0); ASSERT(res);&#125; 对mBlocked起到保护作用1234567891011121314151617181920212223242526272829303132333435363738394041424344454647voidCondition::wait(Mutex&amp; mutex)&#123;#ifndef WIN32 int ret = pthread_cond_wait(&amp;mId, mutex.getId()); ASSERT(ret == 0);#else //1 enterWait(); //2 mutex.unlock(); int res = 0; //3 res = WaitForSingleObject(reinterpret_cast&lt;HANDLE&gt;(mQueue), INFINITE); ASSERT(res == WAIT_OBJECT_0); unsigned wasWaiting = 0; unsigned wasGone = 0; //4 res = WaitForSingleObject(reinterpret_cast&lt;HANDLE&gt;(mMutex), INFINITE); ASSERT(res == WAIT_OBJECT_0); wasWaiting = mWaiting; wasGone = mGone; //signal释放资源后，mWaiting 至少为1 if (wasWaiting != 0) &#123; //判断mWaiting 数量为1 if (--mWaiting == 0) &#123; //如果当前没有阻塞线程则释放mGate if (mBlocked != 0) &#123; res = ReleaseSemaphore(reinterpret_cast&lt;HANDLE&gt;(mGate), 1, 0); // open mGate ASSERT(res); wasWaiting = 0; &#125; &#125; &#125; //5 res = ReleaseMutex(reinterpret_cast&lt;HANDLE&gt;(mMutex)); ASSERT(res); //6 mutex.lock();#endif&#125; 对应的signal函数：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960voidCondition::signal ()&#123;#ifndef WIN32 int ret = pthread_cond_signal(&amp;mId); ASSERT(ret == 0);#else unsigned signals = 0; int res = 0; //1 res = WaitForSingleObject(reinterpret_cast&lt;HANDLE&gt;(mMutex), INFINITE); ASSERT(res == WAIT_OBJECT_0); if (mWaiting != 0) &#123; //当前有空闲的信号量并且没由阻塞的线程 if (mBlocked == 0) &#123; res = ReleaseMutex(reinterpret_cast&lt;HANDLE&gt;(mMutex)); ASSERT(res); return; &#125; //如果由阻塞的线程，那么阻塞数量-- ++mWaiting; --mBlocked; signals = 1; &#125; else &#123; //2当空闲的信号量为0时，互斥获得mGate res = WaitForSingleObject(reinterpret_cast&lt;HANDLE&gt;(mGate), INFINITE); ASSERT(res == WAIT_OBJECT_0); //3 if (mBlocked ) &#123; //如果当前有线程阻塞那么更新计数 signals = mWaiting = 1; --mBlocked; &#125; else &#123; //由于用户外部不判断条件是否成立多次调动signal，此处不处理直接释放mGate res = ReleaseSemaphore(reinterpret_cast&lt;HANDLE&gt;(mGate), 1, 0); ASSERT(res); &#125; &#125; //4 res = ReleaseMutex(reinterpret_cast&lt;HANDLE&gt;(mMutex)); ASSERT(res); //5 if (signals) &#123; res = ReleaseSemaphore(reinterpret_cast&lt;HANDLE&gt;(mQueue), signals, 0); ASSERT(res); &#125;#endif&#125; 到目前为止，对于共享对象的保护和同步都做的比较完善了，还要注意一个问题就是虚假唤醒。这是操作系统可能出现的一种情况，所以需要添加虚假唤醒的逻辑用mGone成员变量表示出错的或是虚假唤醒的线程数最终代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364voidCondition::wait(Mutex&amp; mutex)&#123;#ifndef WIN32 int ret = pthread_cond_wait(&amp;mId, mutex.getId()); ASSERT(ret == 0);#else enterWait(); mutex.unlock(); int res = 0; res = WaitForSingleObject(reinterpret_cast&lt;HANDLE&gt;(mQueue), INFINITE); ASSERT(res == WAIT_OBJECT_0); unsigned wasWaiting = 0; unsigned wasGone = 0; res = WaitForSingleObject(reinterpret_cast&lt;HANDLE&gt;(mMutex), INFINITE); ASSERT(res == WAIT_OBJECT_0); wasWaiting = mWaiting; wasGone = mGone; if (wasWaiting != 0) &#123; if (--mWaiting == 0) &#123; if (mBlocked != 0) &#123; res = ReleaseSemaphore(reinterpret_cast&lt;HANDLE&gt;(mGate), 1, 0); // open mGate ASSERT(res); wasWaiting = 0; &#125; else if (mGone != 0) &#123; mGone = 0; &#125; &#125; &#125; else if (++mGone == (ULONG_MAX / 2)) &#123; res = WaitForSingleObject(reinterpret_cast&lt;HANDLE&gt;(mGate), INFINITE); ASSERT(res == WAIT_OBJECT_0); mBlocked -= mGone; res = ReleaseSemaphore(reinterpret_cast&lt;HANDLE&gt;(mGate), 1, 0); ASSERT(res); mGone = 0; &#125; res = ReleaseMutex(reinterpret_cast&lt;HANDLE&gt;(mMutex)); ASSERT(res); if (wasWaiting == 1) &#123; for (; wasGone; --wasGone) &#123; res = WaitForSingleObject(reinterpret_cast&lt;HANDLE&gt;(mQueue), INFINITE); ASSERT(res == WAIT_OBJECT_0); &#125; res = ReleaseSemaphore(reinterpret_cast&lt;HANDLE&gt;(mGate), 1, 0); ASSERT(res); &#125; mutex.lock();#endif&#125; wait部分添加了mGone的处理，当mWaiting数量为0进入res = WaitForSingleObject(reinterpret_cast(mMutex), INFINITE);需要对mGone++表示虚假唤醒的线程数量123456789if (++mGone == (ULONG_MAX / 2)) &#123; res = WaitForSingleObject(reinterpret_cast&lt;HANDLE&gt;(mGate), INFINITE); ASSERT(res == WAIT_OBJECT_0); mBlocked -= mGone; res = ReleaseSemaphore(reinterpret_cast&lt;HANDLE&gt;(mGate), 1, 0); ASSERT(res); mGone = 0; &#125; 通过mGate对mBlocked保护起来，当唤醒的个数超过指定值会把多余的mblocked去掉并且把虚假唤醒数量置空。举个例子，当mBLocked为1时该线程被虚假唤醒，那么mGone变为1，由于是虚假唤醒，用户在外部调用wait函数时通过while循环判断条件不满足再次进入wait中enterGate函数对mBlocked自增，此时mBlocked数量为2，所以当冗余的mBlocked超过指定值，就回去掉这些mBlocked并将mGone置空。12345678910if (wasWaiting == 1)&#123; for (; wasGone; --wasGone) &#123; res = WaitForSingleObject(reinterpret_cast&lt;HANDLE&gt;(mQueue), INFINITE); ASSERT(res == WAIT_OBJECT_0); &#125; res = ReleaseSemaphore(reinterpret_cast&lt;HANDLE&gt;(mGate), 1, 0); ASSERT(res);&#125; 该函数判断Condation类的mWating变量有1变为0，并且阻塞的线程数为0，因为如果用户没有在外边调用while判断条件导致虚假唤醒引起逻辑错误，所以为了起到保护作用对那些因为虚假唤醒错过的信号进行资源占用，直到信号量都被释放后才进入mGate释放。举一个例子如果外部调用123456789Lock(mutex);if(条件不满足)&#123; wait(mutex); &#125;//逻辑处理 ...UnLock(mutex); 当wait执行退出后会执行逻辑，而没有while判断条件是否真的满足。所以我们要对信号量进行控制，保证信号量数量正确。并且和mBlocked，mWait,等一致。下面是signal函数最终版本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657voidCondition::signal ()&#123;#ifndef WIN32 int ret = pthread_cond_signal(&amp;mId); ASSERT(ret == 0);#else unsigned signals = 0; int res = 0; res = WaitForSingleObject(reinterpret_cast&lt;HANDLE&gt;(mMutex), INFINITE); ASSERT(res == WAIT_OBJECT_0); if (mWaiting != 0) &#123; if (mBlocked == 0) &#123; res = ReleaseMutex(reinterpret_cast&lt;HANDLE&gt;(mMutex)); ASSERT(res); return; &#125; ++mWaiting; --mBlocked; signals = 1; &#125; else &#123; res = WaitForSingleObject(reinterpret_cast&lt;HANDLE&gt;(mGate), INFINITE); ASSERT(res == WAIT_OBJECT_0); if (mBlocked &gt; mGone) &#123; if (mGone != 0) &#123; mBlocked -= mGone; mGone = 0; &#125; signals = mWaiting = 1; --mBlocked; &#125; else &#123; res = ReleaseSemaphore(reinterpret_cast&lt;HANDLE&gt;(mGate), 1, 0); ASSERT(res); &#125; &#125; res = ReleaseMutex(reinterpret_cast&lt;HANDLE&gt;(mMutex)); ASSERT(res); if (signals) &#123; res = ReleaseSemaphore(reinterpret_cast&lt;HANDLE&gt;(mQueue), signals, 0); ASSERT(res); &#125;#endif&#125; 同样的道理12345678910if (mBlocked &gt; mGone) &#123; if (mGone != 0) &#123; mBlocked -= mGone; mGone = 0; &#125; signals = mWaiting = 1; --mBlocked;&#125; 这个逻辑就是处理当虚假唤醒的mBlocked和mGone等数据准确性。因为如果是虚假唤醒，用户通过while(条件不满足)这个方式继续调用wait会导致mBlocked++，假设就一个线程处于阻塞并且因为虚假唤醒通过while循环重新调用wait函数，而此时mGone比mBlocked小1，所以mBlocked - mGone就是更新差值给mBlocked，这是真正的处于阻塞的线程数量。 下面是代码下载地址：betternet 代码效果测试截图：","categories":[{"name":"技术开发","slug":"tech","permalink":"http://www.limerence2017.com/categories/tech/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://www.limerence2017.com/tags/C/"},{"name":"Windows环境编程","slug":"Windows环境编程","permalink":"http://www.limerence2017.com/tags/Windows环境编程/"}]},{"title":"C++类成员空间分配和虚函数表","date":"2017-08-03T06:46:34.000Z","path":"2017/08/03/cppvirtual/","text":"最近在自学python，看到继承和类，就顺便复习了C++的类和继承等方面的知识。先看Base基类123456789101112131415161718class Base &#123;private: virtual void display() &#123; cout&lt;&lt;\"Base display()\"&lt;&lt;endl; &#125; void say()&#123; cout&lt;&lt;\"Base say()\"&lt;&lt;endl; &#125;public: virtual void func()&#123;cout &lt;&lt; \"Base func()\" &lt;&lt; endl; &#125; void exec()&#123; display(); say(); &#125; void f1(string a) &#123; cout&lt;&lt;\"Base f1(string)\"&lt;&lt;endl; &#125; void f1(int a) &#123; cout&lt;&lt;\"Base f1(int)\"&lt;&lt;endl; &#125; //overload&#125;; Base类中定义私有的虚函数display， 普通成员函数say，公共的虚函数func， 普通的成员函数exec，重载了f1函数。下面是DeriveA类，继承于Base类12345678910111213class DeriveA:public Base&#123;public: void display() &#123; cout&lt;&lt;\"DeriveA display()\"&lt;&lt;endl; &#125; //override void f1(int a,int b) &#123; cout&lt;&lt;\"DeriveA f1(int,int)\"&lt;&lt;endl; &#125; //redefining void say() &#123; cout&lt;&lt;\"DeriveA say()\"&lt;&lt;endl; &#125; //redefining virtual void func()&#123;cout &lt;&lt; \"DeriveA func()\" &lt;&lt; endl; &#125;&#125;; DeriveA类继承了Base类，重写(覆盖)了虚函数display和func，并且将display权限修改为public。重定义了f1函数和say函数，但是修改了f1的参数列表。下面是基础的几个测试1234567DeriveA a;Base *b=&amp;a; b-&gt;func(); a.func(); b-&gt;f1(\"abc\"); b-&gt;f1(3); a.f1(3,5); 输出结果:func函数在Base类中为虚函数，DeriveA继承Base后，根据多态机制实现了动态调用。所谓多态机制就是用基类指针指向子类对象，基类指针调用虚函数func，会动态调用实际的子类对象的func函数。由于display函数在Base类中为虚函数，所以不可以通过b-&gt;display()调用。由于DeriveA重新定义(redefining)了f1函数，f1函数参数类型修改了，所以只能使用a.f1(int,int)这种调用，而采用a.f1(string)或者采用a.f1(int)这种调用都会出错，编译阶段就会出错。因为DeriveA类对f1重新定义了，基类的f1函数不可通过对象直接调用。同样的道理对于基类指针或对象，无论基类指针指向子类还是基类对象，调用f1只能调用基类定义的两个f1(int)， f1(string)两个函数，如果采用b-&gt;f1(3,5)，编译器在编译阶段就会提出错误。想实现子类对象调用基类的函数可在函数体内加上作用于Base::函数名(参数，…)DeriveA类修改f1函数，先调用基类的f1在调用自己的f1123456789101112131415161718class DeriveA:public Base&#123;public: void display() &#123; cout&lt;&lt;\"DeriveA display()\"&lt;&lt;endl; &#125; //override void f1(int a,int b) &#123; Base::f1(2); Base::f1(\"test\"); cout&lt;&lt;\"DeriveA f1(int,int)\"&lt;&lt;endl; &#125; //redefining void say() &#123; cout&lt;&lt;\"DeriveA say()\"&lt;&lt;endl; &#125; //redefining virtual void func()&#123; cout &lt;&lt; \"DeriveA func()\" &lt;&lt; endl; &#125;&#125;; 打印输出a.f1(3,5);结果如下：先调用了基类的两个f1函数，之后调用DeriveA的f1函数下面调用如下函数b-&gt;exec();a.exec();结果如下：为什么两个结果一样呢？先看b-&gt;exec()；由于b是Base类型变量，那么调用的Base类的exec函数，exec函数内部调用Base类的display()和say() 函数。由于b为指向DeriveA类的基类指针，根据多态机制，调用Base类的display()函数时，会动态调用DeriveA类的display()函数。调用Base类的say()函数时，由于say()函数不是虚函数，所以不触发多态机制。因此b-&gt;exec()函数的结果为调用DeriveA的display，调用Base的say函数。由于DeriveA类继承于Base类，但是没有实现自己的exec()函数，即没有实现重定义，那么当执行a.exec()时，调用的时Base类的exec()函数，原理和上边一样，调用Base类中的display()函数和say()函数，由于display()函数为虚函数，a为DeriveA类对象，调用基类的虚函数display()，根据多态机制，实际调用的是DeriveA类的display()函数。执行下边代码a.say()结果如下：下面修改DeriveA类的内容，在DeriveA类内部实现自己的exec()函数123456789101112131415161718class DeriveA:public Base&#123;public: void exec()&#123; display(); say(); &#125; void display() &#123; cout&lt;&lt;\"DeriveA display()\"&lt;&lt;endl; &#125; //override void f1(int a,int b) &#123; cout&lt;&lt;\"DeriveA f1(int,int)\"&lt;&lt;endl; &#125; //redefining void say() &#123; cout&lt;&lt;\"DeriveA say()\"&lt;&lt;endl; &#125; //redefining virtual void func()&#123; cout &lt;&lt; \"DeriveA func()\" &lt;&lt; endl; &#125;&#125;; 执行下边代码，b-&gt;exec()；a.exec():结果如下:因为DeriveA类重定义了exec函数，那么a.exec()函数调用的是DeriveA类的exec()函数，从而调用的都是DeriveA类的display()和say()函数。 继承类和基类成员函数调用规则总结：DeriveA a; Base *b=&a; 基类指针指向子类对象，该指针调用某个成员函数，先考虑该函数是否为虚函数，如果为虚函数，且子类有覆盖(重写)，会触发多态机制，动态调用子类的重写函数： 如 b-&gt;func()， 输出为DeriveA func() 基类指针指向子类对象，该指针调用某个成员函数，先考虑该函数是否为虚函数，如果为虚函数，子类没有覆盖(没有重写)，不会触发多态机制，调用基类的虚函数： 基类指针指向子类对象，该指针调用某个成员函数，如果该函数不为虚函数，无论该函数是否被子类重定义(redefined)，只调用基类的该成员函数。如DeriveA类内部不实现exec()函数，那么b-&gt;exec()调用的是Base类的exec()函数。 在第3条基础上，基类有成员函数exec()， 子类没有成员函数exec()，在基类的exec() 内部调用虚函数display()， 且子类覆盖了display()函数，那么根据多态机制，调用子类的display()。如果display()虚函数没有被重写，则调用基类的display()函数，同第2条。如果exec()内部调用普通函数say()， 无论子类是否重定义say()，都会调用基类的say()函数，同3 Base类中实现exec()函数，而子类DeriveA类内部不实现exec()函数，DeriveA类对象调用exec()函数，实际调用的为Base类内部的exec()函数。如果exec()内部调用虚函数或者普通成员函数，情况如同第4条。 Base类中实现exec()函数，而子类DeriveA类重定义exec()函数，那么DeriveA类对象调用的是DeriveA类的exec()函数。如果exec()函数内部调用DeriveA类的其他成员函数，那么调用的都是DeriveA类的成员函数。 子类重定义了基类的成员函数，那么子类对象调用该成员函数，要根据子类重定义的形参列表。如a.f1(3,5); 虚函数使用和定义规则: 非类的成员函数不能定义为虚函数，类的成员函数中静态成员函数和构造函数也不能定义为虚函数，但可以将析构函数定义为虚函数。实际上，优秀的程序员常常把基类的析构函数定义为虚函数。因为，将基类的析构函数定义为虚函数后，当利用delete删除一个指向派生类定义的对象指针时，系统会调用相应的类的析构函数。而不将析构函数定义为虚函数时，只调用基类的析构函数。 只需要在声明函数的类体中使用关键字“virtual”将函数声明为虚函数，而定义函数时不需要使用关键字“virtual”。 如果声明了某个成员函数为虚函数，则在该类中不能出现和这个成员函数同名并且返回值、参数个数、参数类型都相同的非虚函数。在以该类为基类的派生类中，也不能出现这种非虚的同名同返回值同参数个数同参数类型函数。 类的静态函数和构造函数不可以定义为虚函数: 静态函数的目的是通过类名+函数名访问类的static变量，或者通过对象调用staic函数实现对static成员变量的读写，要求内存中只有一份数据。而虚函数在子类中重写，并且通过多态机制实现动态调用，在内存中需要保存不同的重写版本。 构造函数的作用是构造对象，而虚函数的调用是在对象已经构造完成，并且通过调用时动态绑定。动态绑定是因为每个类对象内部都有一个指针，指向虚函数表的首地址。而且虚函数，类的成员函数，static成员函数都不是存储在类对象中，而是在内存中只保留一份。 知其然、知其所以然（虚函数表原理）：虚函数存储在虚函数表中，每个类对象都包含一个指向该虚函数表首地址的指针。定义Baseclass类 123456789class Baseclass &#123; public: Baseclass():a(1024)&#123;&#125; virtual void f() &#123; cout &lt;&lt; \"Base::f\" &lt;&lt; endl; &#125; virtual void g() &#123; cout &lt;&lt; \"Base::g\" &lt;&lt; endl; &#125; virtual void h() &#123; cout &lt;&lt; \"Base::h\" &lt;&lt; endl; &#125; int a;&#125;; 从虚函数表中依次取出函数执行：123456789101112131415161718Baseclass b; cout &lt;&lt;\"类对象大小\" &lt;&lt; sizeof(b) &lt;&lt; endl; int * p = (int *)(&amp;b) ; cout &lt;&lt; \"指向虚函数表的指针的地址\"&lt;&lt; p &lt;&lt; endl; cout &lt;&lt;\"成员a地址\"&lt;&lt; p+1 &lt;&lt; endl; cout &lt;&lt;\"成员a的数值\" &lt;&lt; *(p + 1) &lt;&lt; endl; cout &lt;&lt; \"虚函数表首地址\" &lt;&lt;(int *)(*p) &lt;&lt; endl; Func pFun =(Func) *(int *)(*p); pFun(); pFun =(Func) *((int *)(*p) + 1); pFun(); pFun =(Func) *((int *)(*p) + 2); pFun(); 输出结果如下:可见类对象大小为8字节，4字节正好是指向虚函数表指针的大小。剩余4字节为成员变量a的大小。画个图示意虚函数表结构：p指向的就是类对象的首地址，同时也是虚函数表指针(指向虚函数表的指针)的地址，p指向虚函数表，由于指针是4字节，(int )(p)虚函数表首地址，也是第一个函数指针的地址。Derive类继承于Base类，但是没有覆盖(重写)Base类的虚函数，Derive d; 的虚函数表如下：Derive类继承于Base类，并且覆盖(重写)Base类的虚函数，Derive d; 的虚函数表如下：可以看到d的虚函数表中第一个单元为Derive::f()，覆盖了原有的Base::f()。Derive d;Base p = &d;p指向d的首地址，其实就是d的虚函数表指针的地址，p-&gt;f()实际会调用虚函数表中的Derive::f()，从而实现多态。多重继承结构如下：虚函数表原理后可以篡改部分程序功能，其实很多外挂就是钩子函数回调注入的。12345678910111213141516171819class Baseclass &#123; public: Baseclass():a(1024)&#123;&#125;private: virtual void f() &#123; cout &lt;&lt; \"Base::f\" &lt;&lt; endl; &#125; virtual void g() &#123; cout &lt;&lt; \"Base::g\" &lt;&lt; endl; &#125; virtual void h() &#123; cout &lt;&lt; \"Base::h\" &lt;&lt; endl; &#125; int a;&#125;; class Deriveclass:public Baseclass&#123;public: Deriveclass():Baseclass()&#123;&#125;&#125;; 由于 Baseclass内部的虚函数是私有的，所以Deriveclass类变量是不能直接访问这些函数的。但是可以通过虚函数寻址，并且通过回调函数方式调用。123Deriveclass d; Func pFunc = (Func)*((int *)(*(int *)(&amp;d))); pFunc(); 结果如下： C++类对象的大小为多大？一个类中，虚函数、成员函数（包括静态与非静态）和静态数据成员都是不占用类对象的存储空间的。对象大小= vptr(可能不止一个) + 所有非静态数据成员大小 + Aligin字节大小（依赖于不同的编译器对齐和补齐）定义几个类，然后输出他们大小。12345678910111213141516171819202122232425262728293031323334353637class A &#123; &#125;; class B &#123; char ch; void func() &#123; &#125; &#125;; class C &#123; char ch1; //占用1字节 char ch2; //占用1字节 virtual void func() &#123; &#125; &#125;; class D &#123; int in; virtual void func() &#123; &#125; &#125;; class E&#123; char m; virtual void func() &#123; &#125;&#125;; 输出大小：12345678910A a; B b; C c; D d; E e; cout&lt;&lt;\"a对象大小： \"&lt;&lt; sizeof(a)&lt;&lt;endl; cout&lt;&lt;\"b对象大小： \"&lt;&lt; sizeof(b)&lt;&lt;endl; cout&lt;&lt;\"c对象大小： \" &lt;&lt;sizeof(c)&lt;&lt;endl; cout&lt;&lt;\"d对象大小： \"&lt;&lt; sizeof(d)&lt;&lt;endl; cout &lt;&lt;\"e对象大小： \" &lt;&lt;sizeof(e) &lt;&lt;endl; 结果如下： 类和结构体对象对齐和补齐原则？对齐：类(结构体)对象每个成员分配内存的起始地址为其所占空间的整数倍。补齐：类(结构体)对象所占用的总大小为其内部最大成员所占空间的整数倍。 空类定义的对象a 大小为1因为每个对象是独一无二的，编译器为了标识不同对象，要分配一字节的大小作为标识码。对象b 大小为1是因为成员函数在内存中只存储一份，不会存储在对象中。对象c大小为8， 是因为前四个字节存储虚函数表的指针，第5个字节存储成员变量ch1，第6个字节存储成员变量ch2，这样c的大小为6，根据补齐原则，需要补充2字节，使对象大小为8，8是最大字节4的整数倍。对象d大小为8，不需要补齐和对齐。对象e大小为8，前四个字节存储虚函数表指针，第5个字节存储成员m，需要补齐三个字节，总共八个字节，为4字节的倍数。看看下边这几个类123456789101112131415class F&#123; static int num; &#125;; class G&#123; virtual void print()&#123;&#125; virtual void print1()&#123;&#125; &#125;; class H&#123; void print()&#123;&#125; static void print1()&#123;&#125; &#125;; 打印并输出大小:123456F f;cout&lt;&lt;\"f 对象大小： \"&lt;&lt; sizeof(f)&lt;&lt;endl;G g;cout&lt;&lt;\"g 对象大小： \"&lt;&lt; sizeof(g)&lt;&lt;endl;H h;cout&lt;&lt;\"h 对象大小： \"&lt;&lt; sizeof(h)&lt;&lt;endl; 结果：静态成员变量，虚函数和static成员函数都不会占用对象的空间，f大小为1,是因为要开辟一个字节保存对象标识信息。g大小为4是开辟四字节给虚函数表指针。h大小为1字节也是开辟一个字节保存对象标识信息 什么要采取对齐和补齐分配策略？这个要从计算机CPU存取指令说起，每个字节单元为8bit，从地址0到地址3总共四个字节，为32bit。 class A{ char m; char b; }; A a; 对于a 将a.m分配在地址0开始的一个字节中，将a.b分配在地址1开始的额一个字节中。这样a的大小为2，cpu取数据可以执行一条指令就完成了。class B{ int m; char n; }; B b; 对于b将b.m分配在地址为0开始的四个字节(0~3)，对于b.n分配在开始地址为4的一字节空间。如果再定一个B b2;，不采取补齐策略，b2.m将被分起始地址为5的 4字节空间(5~8)，b2.n就被分在了起始地址为9的一字节空间。cpu取数据需要分3次，先取出0~3地址空间的数据(b.m)，再取出地址4~7数据(b.n和b2.m的前三个字节) 最后取出地址为8~11的数据(b2.m的最后一个字节以及b2.n)。取出数据后还要拆分和组合，极大地降低了效率。所以需要采取补齐策略。补齐策略数据分配如下： 地址0~3存储b.m， 地址4~7存储b.n，由于b.n只占用1个字节，地址5~7不存储数据，用于补齐。 地址8~11存储b2.m，地址12~15存储b2.n，13~15同样不存储数据用于补齐。 这样cpu读取四次可以将数据读取出来，进行简单的组合不需要切割数据就可以完成快速处理。 class C{ char n; int m; } C c； c.n存储周期0开始的一个字节中，如果不采取对齐策略，那么c.m会存储在1~4字节中，这样cpu需要读去两次，并且需要进行切割(0~4地址中数据包含c.n和c.m的前三个字节)，以及组合地址4开始的一个字节(存储c.m的最后一个字节)。 如果采取对齐策略，那么地址0~3存储c.n，地址4~7存储c.m，cpu同样读取两次，但是仅需要组合就可以去除对象的所有数据。 这就是为什么存储数据需要采取对齐和补齐的策略。到此为止C++虚函数和类成员的存储知识复习完，谢谢关注我的公众号：","categories":[{"name":"技术开发","slug":"tech","permalink":"http://www.limerence2017.com/categories/tech/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://www.limerence2017.com/tags/C/"}]}]